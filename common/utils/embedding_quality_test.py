"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ GPU –≤–æ—Ä–∫–µ—Ä–∞
–í–∫–ª—é—á–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import logging
import time
import traceback
from typing import List, Tuple, Optional, Dict, Any
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EmbeddingQualityChecker:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    
    def __init__(self, timeout: int = 60):
        self.timeout = timeout
        self.test_texts = [
            "Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —Å –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≤ ML",
            "Senior Software Engineer with experience in backend development",
            "Data Scientist specializing in machine learning algorithms",
            "Frontend developer skilled in React and TypeScript",
            "DevOps engineer with expertise in cloud platforms"
        ]
    
    def check_embedding_quality(self) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        start_time = time.time()
        result = {
            'success': False,
            'error': None,
            'metrics': {},
            'duration': 0,
            'timestamp': time.time()
        }
        
        try:
            logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
            if not self._check_model_availability():
                raise RuntimeError("–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embeddings = self._generate_test_embeddings()
            if embeddings is None:
                raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            quality_metrics = self._check_embeddings_quality(embeddings)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            performance_metrics = self._check_performance()
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            result['metrics'] = {
                **quality_metrics,
                **performance_metrics
            }
            
            result['success'] = True
            logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {str(e)}"
            logger.error(f"‚ùå {error_msg}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            result['error'] = error_msg
        
        finally:
            result['duration'] = time.time() - start_time
            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {result['duration']:.2f} —Å–µ–∫—É–Ω–¥")
        
        return result
    
    def _check_model_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
            from sentence_transformers import SentenceTransformer
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
            import torch
            if torch.cuda.is_available():
                device = 'cuda'
                logger.info(f"üéØ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.get_device_name()}")
            else:
                device = 'cpu'
                logger.warning("‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model = SentenceTransformer('all-MiniLM-L6-v2', device=device)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
            
            return True
            
        except ImportError as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å sentence_transformers: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def _generate_test_embeddings(self) -> Optional[np.ndarray]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            from sentence_transformers import SentenceTransformer
            import torch
            
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            model = SentenceTransformer('all-MiniLM-L6-v2', device=device)
            
            logger.info(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(self.test_texts)} —Ç–µ–∫—Å—Ç–æ–≤...")
            
            start_time = time.time()
            embeddings = model.encode(self.test_texts, convert_to_numpy=True)
            generation_time = time.time() - start_time
            
            logger.info(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∑–∞ {generation_time:.2f} —Å–µ–∫—É–Ω–¥")
            logger.info(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embeddings.shape}")
            
            return embeddings
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return None
    
    def _check_embeddings_quality(self, embeddings: np.ndarray) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            metrics = {}
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            metrics['dimension'] = embeddings.shape[1]
            metrics['num_samples'] = embeddings.shape[0]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å
            nan_count = np.isnan(embeddings).sum()
            inf_count = np.isinf(embeddings).sum()
            
            metrics['nan_count'] = int(nan_count)
            metrics['inf_count'] = int(inf_count)
            metrics['has_invalid_values'] = nan_count > 0 or inf_count > 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            metrics['mean_magnitude'] = float(np.linalg.norm(embeddings, axis=1).mean())
            metrics['std_magnitude'] = float(np.linalg.norm(embeddings, axis=1).std())
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            similarity_matrix = np.dot(embeddings, embeddings.T)
            np.fill_diagonal(similarity_matrix, 0)  # –£–±–∏—Ä–∞–µ–º —Å–∞–º–æ–ø–æ–¥–æ–±–∏–µ
            
            metrics['max_similarity'] = float(similarity_matrix.max())
            metrics['avg_similarity'] = float(similarity_matrix.mean())
            metrics['min_similarity'] = float(similarity_matrix.min())
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            quality_score = self._calculate_quality_score(metrics)
            metrics['quality_score'] = quality_score
            
            if quality_score > 0.7:
                logger.info(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ö–æ—Ä–æ—à–µ–µ: {quality_score:.3f}")
            elif quality_score > 0.5:
                logger.warning(f"‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å—Ä–µ–¥–Ω–µ–µ: {quality_score:.3f}")
            else:
                logger.error(f"‚ùå –ö–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–∏–∑–∫–æ–µ: {quality_score:.3f}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return {'error': str(e)}
    
    def _calculate_quality_score(self, metrics: Dict[str, float]) -> float:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            score = 1.0
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if metrics.get('has_invalid_values', False):
                score *= 0.1
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫—É—é –∏–ª–∏ –≤—ã—Å–æ–∫—É—é –≤–µ–ª–∏—á–∏–Ω—É
            mean_mag = metrics.get('mean_magnitude', 0)
            if mean_mag < 0.1 or mean_mag > 100:
                score *= 0.5
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)
            max_sim = metrics.get('max_similarity', 0)
            if max_sim > 0.95:
                score *= 0.7
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            avg_sim = metrics.get('avg_similarity', 0)
            if avg_sim < 0.1:
                score *= 0.8
            
            return max(0.0, min(1.0, score))
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
            return 0.0
    
    def _check_performance(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            from sentence_transformers import SentenceTransformer
            import torch
            
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            model = SentenceTransformer('all-MiniLM-L6-v2', device=device)
            
            # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            test_sizes = [1, 10, 50, 100]
            performance_metrics = {}
            
            for size in test_sizes:
                test_texts = self.test_texts[:min(size, len(self.test_texts))]
                if len(test_texts) < size:
                    test_texts = test_texts * (size // len(test_texts) + 1)
                    test_texts = test_texts[:size]
                
                start_time = time.time()
                embeddings = model.encode(test_texts, convert_to_numpy=True)
                end_time = time.time()
                
                duration = end_time - start_time
                throughput = size / duration if duration > 0 else 0
                
                performance_metrics[f'throughput_{size}_texts'] = throughput
                performance_metrics[f'latency_{size}_texts'] = duration
            
            logger.info(f"üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {performance_metrics}")
            return performance_metrics
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return {'performance_error': str(e)}


def check_embedding_quality(timeout: int = 60) -> Dict[str, Any]:
    """
    –ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    
    Args:
        timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    checker = EmbeddingQualityChecker(timeout=timeout)
    return checker.check_embedding_quality()


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ –ø—Ä—è–º–æ–º –∑–∞–ø—É—Å–∫–µ
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    result = check_embedding_quality()
    
    if result['success']:
        print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")
        print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏: {result['metrics']}")
    else:
        print(f"‚ùå –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {result['error']}")
    
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result['duration']:.2f} —Å–µ–∫—É–Ω–¥")

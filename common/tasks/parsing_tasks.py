"""
Parsing tasks for extracting text from resume and job description files
"""

import os
import requests
import re
from datetime import datetime
from typing import Dict, List, Any, Optional
from celery.utils.log import get_task_logger
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from sqlalchemy import text

from common.celery_app.celery_app import celery_app
from common.database.config import database
from common.models.candidates import Submission
from common.models.companies import Job

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = get_task_logger(__name__)


@celery_app.task(
    bind=True,
    name='common.tasks.parsing_tasks.parse_resume_text',
    soft_time_limit=1800,
    time_limit=2100,
    max_retries=2
)
def parse_resume_text(self, previous_results=None) -> Dict[str, Any]:
    """
    Task 2A: –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ–∑—é–º–µ –∏–∑ —Ñ–∞–π–ª–æ–≤ PDF/DOC/DOCX
    
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ submissions –≥–¥–µ –µ—Å—Ç—å resume_url –Ω–æ –Ω–µ—Ç resume_raw_text
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, —Å—Ç–∞—Ç—É—Å
    """
    logger.info("üìÑ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ–∑—é–º–µ")
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
    if previous_results:
        logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞: {previous_results}")
    
    try:
        db = database.get_session()
        processed_count = 0
        error_count = 0
        
        try:
            # –ù–∞—Ö–æ–¥–∏–º submissions —Å URL —Ñ–∞–π–ª–∞, –Ω–æ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞
            submissions_to_process = db.query(Submission).filter(
                Submission.resume_url.isnot(None),
                Submission.resume_url != '',
                Submission.resume_raw_text.is_(None)
            ).all()
            
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(submissions_to_process)} —Ä–µ–∑—é–º–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
            
            for submission in submissions_to_process:
                try:
                    logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Ä–µ–∑—é–º–µ: {submission.submission_id}")
                    
                    # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
                    extracted_text = _extract_text_from_url(str(submission.resume_url))
                    
                    if extracted_text:
                        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
                        cleaned_text = _clean_extracted_text(extracted_text)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
                        setattr(submission, 'resume_raw_text', cleaned_text)
                        db.commit()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç–∏
                        processed_count += 1
                        
                        logger.info(f"‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(cleaned_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ {submission.resume_url}")
                        error_count += 1
                        
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ {submission.submission_id}: {e}")
                    error_count += 1
                    # –û—Ç–∫–∞—Ç—ã–≤–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                    db.rollback()
                    continue
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            if db.in_transaction():
                db.commit()
            
            logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—é–º–µ –∑–∞–≤–µ—Ä—à–µ–Ω: {processed_count} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, {error_count} –æ—à–∏–±–æ–∫")
            
            return {
                'status': 'completed',
                'processed_files': processed_count,
                'error_files': error_count,
                'total_found': len(submissions_to_process)
            }
            
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—é–º–µ: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'processed_files': 0,
            'error_files': 0
        }


@celery_app.task(
    bind=True,
    name='common.tasks.parsing_tasks.parse_job_text',
    soft_time_limit=1800,
    time_limit=2100,
    max_retries=2
)
def parse_job_text(self, previous_results=None) -> Dict[str, Any]:
    """
    Task 2B: –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤ –æ–ø–∏—Å–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ —Ñ–∞–π–ª–æ–≤
    
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ jobs —Å job_description_url, –Ω–æ –±–µ–∑ job_description_raw_text
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, —Å—Ç–∞—Ç—É—Å
    """
    logger.info("üìÑ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π")
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
    if previous_results:
        logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞: {previous_results}")
    
    try:
        db = database.get_session()
        processed_count = 0
        error_count = 0
        
        try:
            # –ù–∞—Ö–æ–¥–∏–º jobs —Å URL —Ñ–∞–π–ª–∞, –Ω–æ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞
            jobs_to_process = db.query(Job).filter(
                Job.job_description_url.isnot(None),
                Job.job_description_url != '',
                Job.job_description_raw_text.is_(None)
            ).all()
            
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(jobs_to_process)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
            
            for job in jobs_to_process:
                try:
                    logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –≤–∞–∫–∞–Ω—Å–∏–∏: {job.job_id}")
                    
                    # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
                    extracted_text = _extract_text_from_url(str(job.job_description_url))
                    
                    if extracted_text:
                        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
                        cleaned_text = _clean_extracted_text(extracted_text)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
                        setattr(job, 'job_description_raw_text', cleaned_text)
                        db.commit()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç–∏
                        processed_count += 1
                        
                        logger.info(f"‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(cleaned_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ {job.job_description_url}")
                        error_count += 1
                        
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: {e}")
                    error_count += 1
                    # –û—Ç–∫–∞—Ç—ã–≤–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                    db.rollback()
                    continue
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            if db.in_transaction():
                db.commit()
            
            logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω: {processed_count} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, {error_count} –æ—à–∏–±–æ–∫")
            
            return {
                'status': 'completed',
                'processed_files': processed_count,
                'error_files': error_count,
                'total_found': len(jobs_to_process)
            }
            
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'processed_files': 0,
            'error_files': 0
        }


def _extract_text_from_url(file_url: str) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –ø–æ URL
    
    Args:
        file_url: URL —Ñ–∞–π–ª–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not file_url or not file_url.startswith(('http://', 'https://')):
        logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL: {file_url}")
        return None
    
    try:
        logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {file_url}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
        response = requests.get(file_url, timeout=30)
        response.raise_for_status()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ URL –∏–ª–∏ Content-Type
        content_type = response.headers.get('content-type', '').lower()
        file_extension = _get_file_extension(file_url, content_type)
        
        logger.info(f"üìã –¢–∏–ø —Ñ–∞–π–ª–∞: {file_extension}, –†–∞–∑–º–µ—Ä: {len(response.content)} –±–∞–π—Ç")
        
        # –ü–∞—Ä—Å–∏–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if file_extension == 'pdf':
            return _extract_pdf_text(response.content)
        elif file_extension in ['doc', 'docx']:
            return _extract_docx_text(response.content)
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_extension}")
            return None
            
    except requests.RequestException as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_url}: {e}")
        return None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_url}: {e}")
        return None


def _get_file_extension(url: str, content_type: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ URL –∏–ª–∏ Content-Type"""
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ URL
    if url.lower().endswith('.pdf'):
        return 'pdf'
    elif url.lower().endswith(('.doc', '.docx')):
        return 'docx'
    
    # –ó–∞—Ç–µ–º –ø–æ Content-Type
    if 'pdf' in content_type:
        return 'pdf'
    elif 'word' in content_type or 'officedocument' in content_type:
        return 'docx'
    elif 'msword' in content_type:
        return 'doc'
    
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–±—É–µ–º PDF
    return 'pdf'


def _extract_pdf_text(pdf_content: bytes) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞ —Å fallback –º–µ—Ç–æ–¥–∞–º–∏
    
    Args:
        pdf_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ PDF —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
        
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None
    """
    # –ü—Ä–æ–±—É–µ–º PyMuPDF —Å–Ω–∞—á–∞–ª–∞
    result = _extract_pdf_with_fitz(pdf_content)
    if result:
        return result
    
    # Fallback –Ω–∞ PyPDF2
    logger.info("üîÑ –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ PyPDF2 –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞")
    return _extract_pdf_with_pypdf2(pdf_content)


def _extract_pdf_with_fitz(pdf_content: bytes) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é PyMuPDF"""
    doc = None
    try:
        import fitz  # PyMuPDF
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º PDF –∏–∑ –ø–∞–º—è—Ç–∏
        doc = fitz.open(stream=pdf_content, filetype="pdf")
        text_parts = []
        page_count = doc.page_count
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        for page_num in range(page_count):
            try:
                page = doc[page_num]
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π API PyMuPDF –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
                text = page.get_text()  # type: ignore
                if text and text.strip():
                    text_parts.append(text.strip())
            except Exception as page_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num + 1}: {page_error}")
                continue
        
        if text_parts:
            full_text = '\n\n'.join(text_parts)
            logger.info(f"üìÑ PDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω PyMuPDF: {page_count} —Å—Ç—Ä–∞–Ω–∏—Ü, {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return full_text
        else:
            logger.warning("‚ö†Ô∏è PyMuPDF: PDF –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–ª–µ–∫–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
            return None
            
    except ImportError:
        logger.warning("‚ö†Ô∏è PyMuPDF –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        return None
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ PyMuPDF: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        return None
    finally:
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        if doc is not None:
            try:
                doc.close()
            except Exception as close_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è PDF: {close_error}")


def _extract_pdf_with_pypdf2(pdf_content: bytes) -> Optional[str]:
    """Fallback –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é PyPDF2"""
    try:
        import PyPDF2
        from io import BytesIO
        
        pdf_stream = BytesIO(pdf_content)
        pdf_reader = PyPDF2.PdfReader(pdf_stream)
        text_parts = []
        
        for page_num, page in enumerate(pdf_reader.pages):
            try:
                text = page.extract_text()
                if text and text.strip():
                    text_parts.append(text.strip())
            except Exception as page_error:
                logger.warning(f"‚ö†Ô∏è PyPDF2: –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num + 1}: {page_error}")
                continue
        
        if text_parts:
            full_text = '\n\n'.join(text_parts)
            logger.info(f"üìÑ PDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω PyPDF2: {len(pdf_reader.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü, {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return full_text
        else:
            logger.warning("‚ö†Ô∏è PyPDF2: PDF –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–ª–µ–∫–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
            return None
            
    except ImportError:
        logger.error("‚ùå PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install PyPDF2")
        return None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ PyPDF2: {e}")
        return None


def _extract_docx_text(docx_content: bytes) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOCX/DOC —Ñ–∞–π–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
    
    Args:
        docx_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ DOCX/DOC —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
        
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π DOCX —Ñ–æ—Ä–º–∞—Ç
    result = _extract_modern_docx(docx_content)
    if result:
        return result
    
    # Fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö DOC —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö DOCX
    logger.info("üîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOC")
    return _extract_legacy_doc_text(docx_content)


def _extract_modern_docx(docx_content: bytes) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ DOCX —Ñ–æ—Ä–º–∞—Ç–∞"""
    try:
        import docx
        from io import BytesIO
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º DOCX –∏–∑ –ø–∞–º—è—Ç–∏
        doc = docx.Document(BytesIO(docx_content))
        text_parts = []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if text:
                text_parts.append(text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    text = cell.text.strip()
                    if text:
                        text_parts.append(text)
        
        if text_parts:
            full_text = '\n'.join(text_parts)
            logger.info(f"üìÑ DOCX –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(doc.paragraphs)} –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤, {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return full_text
        else:
            logger.warning("‚ö†Ô∏è DOCX –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
            return None
            
    except ImportError:
        logger.error("‚ùå python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
        return None
    except Exception as e:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ª—é–±—ã–µ –æ—à–∏–±–∫–∏, –≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–ª–µ–º—ã —Å —Ñ–æ—Ä–º–∞—Ç–æ–º —Ñ–∞–π–ª–∞
        if "not a zip file" in str(e).lower() or "bad zipfile" in str(e).lower():
            logger.warning("‚ö†Ô∏è –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º DOCX –¥–æ–∫—É–º–µ–Ω—Ç–æ–º, –ø—Ä–æ–±—É–µ–º legacy –º–µ—Ç–æ–¥—ã")
        else:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX: {e}, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã")
        return None


def _extract_legacy_doc_text(doc_content: bytes) -> Optional[str]:
    """Fallback –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å—Ç–∞—Ä—ã—Ö DOC —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å antiword –¥–ª—è DOC —Ñ–∞–π–ª–æ–≤
        text_result = _extract_with_antiword(doc_content)
        if text_result:
            return text_result
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å olefile –¥–ª—è —á—Ç–µ–Ω–∏—è OLE —Å—Ç—Ä—É–∫—Ç—É—Ä—ã DOC
        text_result = _extract_with_olefile(doc_content)
        if text_result:
            return text_result
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # (—Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å—Ç–∞—Ä—ã—Ö DOC —Ñ–∞–π–ª–æ–≤)
        text_content = _extract_text_from_binary(doc_content)
        if text_content:
            logger.info(f"üìÑ DOC –æ–±—Ä–∞–±–æ—Ç–∞–Ω –±–∏–Ω–∞—Ä–Ω—ã–º –º–µ—Ç–æ–¥–æ–º: {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤")
            return text_content
        
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –Ω–∏ –æ–¥–Ω–∏–º –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤")
        return None
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ legacy DOC: {e}")
        return None


def _extract_with_antiword(doc_content: bytes) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é antiword –±–∏–±–ª–∏–æ—Ç–µ–∫–∏"""
    try:
        import tempfile
        import subprocess
        import os
        
        # antiword —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –∫–æ–º–∞–Ω–¥–Ω–∞—è —É—Ç–∏–ª–∏—Ç–∞, —Å–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(suffix='.doc', delete=False) as temp_file:
            temp_file.write(doc_content)
            temp_file.flush()
            
            try:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å antiword —á–µ—Ä–µ–∑ subprocess
                try:
                    result = subprocess.run(
                        ['antiword', temp_file.name],
                        capture_output=True,
                        text=True,
                        timeout=30
                    )
                    if result.returncode == 0 and result.stdout.strip():
                        text = result.stdout.strip()
                        logger.info(f"üìÑ DOC –æ–±—Ä–∞–±–æ—Ç–∞–Ω antiword CLI: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return text
                except (subprocess.TimeoutExpired, FileNotFoundError):
                    logger.warning("‚ö†Ô∏è antiword CLI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                    
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                try:
                    os.unlink(temp_file.name)
                except:
                    pass
                    
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è antiword –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")
        return None


def _extract_with_olefile(doc_content: bytes) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é olefile –¥–ª—è —á—Ç–µ–Ω–∏—è OLE —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    try:
        import olefile
        from io import BytesIO
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª OLE –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        if not olefile.isOleFile(BytesIO(doc_content)):
            logger.warning("‚ö†Ô∏è –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è OLE –¥–æ–∫—É–º–µ–Ω—Ç–æ–º")
            return None
        
        ole = olefile.OleFileIO(BytesIO(doc_content))
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
            all_streams = ole.listdir()
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ –≤ DOC —Ñ–∞–π–ª–µ: {all_streams[:10]}...")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            
            found_text = []
            
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞
            priority_streams = ['WordDocument', '1Table', 'Data', 'CompObj']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–æ—Ç–æ–∫–∏
            for stream_name in priority_streams:
                if ole.exists(stream_name):
                    try:
                        stream_data = ole.openstream(stream_name).read()
                        
                        if stream_data and len(stream_data) > 100:
                            text_parts = _extract_readable_text_from_bytes(stream_data)
                            if text_parts:
                                found_text.extend(text_parts)
                                logger.info(f"ÔøΩ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –≤ –ø–æ—Ç–æ–∫–µ {stream_name}: {len(text_parts)} —á–∞—Å—Ç–µ–π")
                                
                    except Exception as stream_error:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ {stream_name}: {stream_error}")
                        continue
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö, –ø–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ
            if not found_text:
                for stream_info in all_streams:
                    try:
                        stream_name = stream_info[0] if isinstance(stream_info, list) else stream_info
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ—Ç–æ–∫–∏
                        if stream_name.startswith(('__', '\x01', '\x03', '\x05')):
                            continue
                            
                        if ole.exists(stream_name):
                            stream_data = ole.openstream(stream_name).read()
                            
                            if stream_data and len(stream_data) > 100:
                                text_parts = _extract_readable_text_from_bytes(stream_data)
                                if text_parts:
                                    found_text.extend(text_parts)
                                    logger.info(f"üìÑ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –≤ –ø–æ—Ç–æ–∫–µ {stream_name}: {len(text_parts)} —á–∞—Å—Ç–µ–π")
                                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞, –º–æ–∂–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                                    if len(' '.join(found_text)) > 500:
                                        break
                                        
                    except Exception:
                        continue
            
            if found_text:
                text = ' '.join(found_text)
                text = re.sub(r'\s+', ' ', text).strip()
                if len(text) > 50:
                    logger.info(f"üìÑ DOC –æ–±—Ä–∞–±–æ—Ç–∞–Ω olefile: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return text
                        
        finally:
            ole.close()
            
    except ImportError:
        logger.warning("‚ö†Ô∏è olefile –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        return None
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è olefile –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")
        return None


def _extract_readable_text_from_bytes(data: bytes) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –±–∞–π—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    text_parts = []
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
    encodings = ['utf-16le', 'utf-16be', 'utf-8', 'latin-1', 'cp1252', 'cp1251']
    
    for encoding in encodings:
        try:
            decoded = data.decode(encoding, errors='ignore')
            # –ò—â–µ–º —á–∏—Ç–∞–µ–º—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞—Å—Ç–∏ (–º–∏–Ω–∏–º—É–º 5 —Å–∏–º–≤–æ–ª–æ–≤)
            import re
            readable_parts = re.findall(r'[A-Za-z][A-Za-z0-9\s\.,;:!?\-()]{4,}', decoded)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏
            valid_parts = []
            for part in readable_parts:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –±—É–∫–≤ –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∏–º–≤–æ–ª–æ–≤
                letters = len(re.findall(r'[A-Za-z]', part))
                if letters > len(part) * 0.3:  # –ú–∏–Ω–∏–º—É–º 30% –±—É–∫–≤
                    valid_parts.append(part.strip())
            
            if valid_parts:
                text_parts.extend(valid_parts)
                
        except Exception:
            continue
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞—Å—Ç–∏
    unique_parts = []
    for part in text_parts:
        if len(part) > 10 and part not in unique_parts:
            unique_parts.append(part)
    
    return unique_parts


def _extract_text_from_binary(binary_content: bytes) -> Optional[str]:
    """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö DOC —Ñ–∞–π–ª–∞"""
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        encodings = ['utf-8', 'utf-16', 'latin-1', 'cp1252', 'iso-8859-1']
        
        for encoding in encodings:
            try:
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫
                raw_text = binary_content.decode(encoding, errors='ignore')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç (–º–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞ –ø–æ–¥—Ä—è–¥)
                import re
                text_parts = re.findall(r'[A-Za-z0-9\s\.,;:!?\-()]{3,}', raw_text)
                
                if text_parts:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏
                    extracted_text = ' '.join(text_parts)
                    
                    # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
                    extracted_text = re.sub(r'\s+', ' ', extracted_text).strip()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª—Å—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    if len(extracted_text) > 50 and len(extracted_text.split()) > 10:
                        logger.info(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω —Ç–µ–∫—Å—Ç –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}: {len(extracted_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return extracted_text
                        
            except Exception as e:
                continue
        
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        return None
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        return None


def _clean_extracted_text(raw_text: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    
    Args:
        raw_text: –°—ã—Ä–æ–π –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not raw_text:
        return ""
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫
    text = re.sub(r'\r\n|\r', '\n', raw_text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ —Ç–∞–±—É–ª—è—Ü–∏–π
    text = re.sub(r'[ \t]+', ' ', text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ (–±–æ–ª—å—à–µ 2 –ø–æ–¥—Ä—è–¥)
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
    lines = [line.strip() for line in text.split('\n')]
    text = '\n'.join(lines)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ (–ø—Ä–æ—Å—Ç–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Å–æ—Å–µ–¥–Ω–∏—Ö —Å—Ç—Ä–æ–∫)
    lines = text.split('\n')
    cleaned_lines = []
    previous_line = None
    
    for line in lines:
        if line != previous_line or len(line.strip()) > 50:  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–∞–∂–µ –µ—Å–ª–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã
            cleaned_lines.append(line)
        previous_line = line
    
    text = '\n'.join(cleaned_lines)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
    text = text.strip()
    
    # –£–¥–∞–ª—è–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã (–º–µ–Ω–µ–µ 10 —Å–∏–º–≤–æ–ª–æ–≤)
    if len(text) < 10:
        logger.warning("‚ö†Ô∏è –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
        return ""
    
    logger.info(f"üßπ –¢–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω: {len(raw_text)} ‚Üí {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
    return text

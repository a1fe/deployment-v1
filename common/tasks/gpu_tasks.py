"""
GPU-related tasks for HR analysis system
"""

import os
import time
import requests
import psutil
from typing import Dict, Any, Optional
from celery import Celery
from celery.utils.log import get_task_logger

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä Celery
# –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis —á–µ—Ä–µ–∑ Secret Manager
from deployment.common.utils.secret_manager import get_redis_url_with_auth
redis_url = get_redis_url_with_auth()
app = Celery('hr_analysis', broker=redis_url, backend=redis_url)
logger = get_task_logger(__name__)


@app.task(
    bind=True,
    name='tasks.gpu_tasks.check_and_start_gpu_server',
    soft_time_limit=300,  # 5 –º–∏–Ω—É—Ç
    time_limit=360,       # 6 –º–∏–Ω—É—Ç
    max_retries=3
)
def check_and_start_gpu_server(self, required_for: str = 'ai_analysis') -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU —Å–µ—Ä–≤–µ—Ä–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –µ–≥–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    
    Args:
        required_for: –î–ª—è –∫–∞–∫–æ–π –∑–∞–¥–∞—á–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è GPU ('ai_analysis', 'embedding', etc.)
    
    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–∞—Ç—É—Å–µ GPU —Å–µ—Ä–≤–µ—Ä–∞
    """
    logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ GPU —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –∑–∞–¥–∞—á–∏: {required_for}")
    
    try:
        gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8001')
        health_endpoint = f"{gpu_server_url}/health"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(
            state='PROGRESS',
            meta={
                'progress': 10,
                'status': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU —Å–µ—Ä–≤–µ—Ä–∞',
                'required_for': required_for
            }
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU —Å–µ—Ä–≤–µ—Ä–∞
        try:
            response = requests.get(health_endpoint, timeout=10)
            if response.status_code == 200:
                gpu_info = response.json()
                logger.info(f"‚úÖ GPU —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_info}")
                
                self.update_state(
                    state='SUCCESS',
                    meta={
                        'progress': 100,
                        'status': 'GPU —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω',
                        'gpu_info': gpu_info
                    }
                )
                
                return {
                    'status': 'available',
                    'server_url': gpu_server_url,
                    'gpu_info': gpu_info,
                    'action': 'none',
                    'required_for': required_for
                }
        except requests.RequestException:
            logger.warning("‚ö†Ô∏è GPU —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞")
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ GPU —Å–µ—Ä–≤–µ—Ä–∞
        startup_script = os.getenv('GPU_STARTUP_SCRIPT', '/opt/gpu-server/start.sh')
        if os.path.exists(startup_script):
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ GPU —Å–µ—Ä–≤–µ—Ä–∞: {startup_script}")
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ process_executor
            from deployment.common.utils.process_executor import start_background_service
            
            result = start_background_service(['bash', startup_script])
            if not result.get('success', False):
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ GPU —Å–µ—Ä–≤–µ—Ä–∞: {result.get('error', 'Unknown error')}")
                return {
                    'status': 'error',
                    'error': f"Failed to start GPU server: {result.get('error', 'Unknown error')}"
                }
            
            logger.info(f"‚úÖ GPU —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω, PID: {result.get('pid')}")
            
            # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞ (–¥–æ 60 —Å–µ–∫—É–Ω–¥)
            for i in range(12):  # 12 –ø–æ–ø—ã—Ç–æ–∫ –ø–æ 5 —Å–µ–∫—É–Ω–¥
                time.sleep(5)
                try:
                    response = requests.get(health_endpoint, timeout=5)
                    if response.status_code == 200:
                        gpu_info = response.json()
                        logger.info(f"‚úÖ GPU —Å–µ—Ä–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω: {gpu_info}")
                        return {
                            'status': 'started',
                            'server_url': gpu_server_url,
                            'gpu_info': gpu_info,
                            'action': 'started',
                            'startup_time': (i + 1) * 5
                        }
                except requests.RequestException:
                    continue
            
            logger.error("‚ùå GPU —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ 60 —Å–µ–∫—É–Ω–¥")
            return {
                'status': 'failed',
                'server_url': gpu_server_url,
                'action': 'start_failed',
                'error': 'Timeout waiting for GPU server startup'
            }
        else:
            logger.warning(f"‚ö†Ô∏è –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞ GPU –Ω–µ –Ω–∞–π–¥–µ–Ω: {startup_script}")
            return {
                'status': 'unavailable',
                'server_url': gpu_server_url,
                'action': 'script_not_found',
                'error': f'Startup script not found: {startup_script}'
            }
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU —Å–µ—Ä–≤–µ—Ä–∞: {e}")
        return {
            'status': 'error',
            'action': 'check_failed',
            'error': str(e)
        }


@app.task(
    bind=True,
    name='tasks.gpu_tasks.ai_analysis_task',
    soft_time_limit=600,  # 10 –º–∏–Ω—É—Ç
    time_limit=720,       # 12 –º–∏–Ω—É—Ç
    max_retries=2
)
def ai_analysis_task(self, analysis_data: Dict[str, Any], gpu_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç AI-–∞–Ω–∞–ª–∏–∑ –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä–µ
    
    Args:
        analysis_data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞, –º–∞—Ç—á–∏–Ω–≥–∞ –∏ —Ç.–¥.)
        gpu_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU —Å–µ—Ä–≤–µ—Ä–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ AI-–∞–Ω–∞–ª–∏–∑–∞
    """
    logger.info("üß† –ó–∞–ø—É—Å–∫ AI-–∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä–µ")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –Ω–∞ GPU
        if gpu_info and gpu_info.get('status') != 'available':
            logger.warning("‚ö†Ô∏è GPU —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º AI-–∞–Ω–∞–ª–∏–∑")
            return {
                'status': 'skipped',
                'reason': 'GPU server unavailable',
                'gpu_info': gpu_info
            }
        
        gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8001')
        analysis_endpoint = f"{gpu_server_url}/analyze"
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_request = {
            'analysis_type': analysis_data.get('analysis_type', 'reranking_analysis'),
            'data': analysis_data,
            'model_config': {
                'use_gpu': True,
                'batch_size': int(os.getenv('AI_BATCH_SIZE', '8')),
                'max_length': int(os.getenv('AI_MAX_LENGTH', '512'))
            }
        }
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPU —Å–µ—Ä–≤–µ—Ä—É
        logger.info(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä: {analysis_endpoint}")
        response = requests.post(
            analysis_endpoint,
            json=analysis_request,
            timeout=300,  # 5 –º–∏–Ω—É—Ç –Ω–∞ –∞–Ω–∞–ª–∏–∑
            headers={'Content-Type': 'application/json'}
        )
        
        if response.status_code == 200:
            analysis_result = response.json()
            logger.info("‚úÖ AI-–∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            return {
                'status': 'completed',
                'analysis_result': analysis_result,
                'gpu_info': gpu_info,
                'processing_time': analysis_result.get('processing_time', 0)
            }
        else:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: HTTP {response.status_code}")
            return {
                'status': 'error',
                'error': f'HTTP {response.status_code}: {response.text}',
                'gpu_info': gpu_info
            }
    
    except requests.RequestException as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å GPU —Å–µ—Ä–≤–µ—Ä–æ–º: {e}")
        return {
            'status': 'connection_error',
            'error': str(e),
            'gpu_info': gpu_info
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'gpu_info': gpu_info
        }


@app.task(
    bind=True,
    name='tasks.gpu_tasks.get_gpu_status',
    soft_time_limit=30,   # 30 —Å–µ–∫—É–Ω–¥
    time_limit=60         # 1 –º–∏–Ω—É—Ç–∞
)
def get_gpu_status(self) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å GPU —Ä–µ—Å—É—Ä—Å–æ–≤
    
    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–∞—Ç—É—Å–µ GPU
    """
    logger.info("üìä –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ GPU")
    
    try:
        gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8001')
        status_endpoint = f"{gpu_server_url}/status"
        
        response = requests.get(status_endpoint, timeout=10)
        if response.status_code == 200:
            status_info = response.json()
            logger.info(f"üìä –°—Ç–∞—Ç—É—Å GPU –ø–æ–ª—É—á–µ–Ω: {status_info}")
            return {
                'status': 'available',
                'gpu_status': status_info,
                'server_url': gpu_server_url
            }
        else:
            logger.warning(f"‚ö†Ô∏è GPU —Å–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}")
            return {
                'status': 'unavailable',
                'error': f'HTTP {response.status_code}',
                'server_url': gpu_server_url
            }
    
    except requests.RequestException as e:
        logger.warning(f"‚ö†Ô∏è GPU —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return {
            'status': 'unavailable',
            'error': str(e),
            'server_url': gpu_server_url
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ GPU: {e}")
        return {
            'status': 'error',
            'error': str(e)
        }


@app.task(
    bind=True,
    name='tasks.gpu_tasks.ai_analysis',
    soft_time_limit=900,  # 15 –º–∏–Ω—É—Ç
    time_limit=1080,      # 18 –º–∏–Ω—É—Ç
    max_retries=2
)
def ai_analysis(self, documents_data: Dict[str, Any], analysis_type: str = 'match_scoring') -> Dict[str, Any]:
    """
    AI –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä–µ
    
    Args:
        documents_data: –î–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_type: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞ ('match_scoring', 'skills_extraction', 'sentiment_analysis')
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ AI –∞–Ω–∞–ª–∏–∑–∞
    """
    from datetime import datetime
    
    logger.info(f"ü§ñ –ó–∞–ø—É—Å–∫ AI –∞–Ω–∞–ª–∏–∑–∞ —Ç–∏–ø–∞ '{analysis_type}' –¥–ª—è {len(documents_data.get('documents', []))} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    try:
        gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8001')
        analysis_endpoint = f"{gpu_server_url}/ai/analyze"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(
            state='PROGRESS',
            meta={
                'progress': 10,
                'status': f'–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞ —Ç–∏–ø–∞ {analysis_type}',
                'analysis_type': analysis_type
            }
        )
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_request = {
            'documents': documents_data.get('documents', []),
            'analysis_type': analysis_type,
            'options': {
                'include_confidence': True,
                'detailed_results': True,
                'batch_size': 10  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            }
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(
            state='PROGRESS',
            meta={
                'progress': 30,
                'status': '–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞',
                'documents_count': len(documents_data.get('documents', []))
            }
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä
        response = requests.post(
            analysis_endpoint,
            json=analysis_request,
            timeout=900,  # 15 –º–∏–Ω—É—Ç
            headers={'Content-Type': 'application/json'}
        )
        
        if response.status_code == 200:
            analysis_results = response.json()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            self.update_state(
                state='PROGRESS',
                meta={
                    'progress': 80,
                    'status': '–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ AI –∞–Ω–∞–ª–∏–∑–∞',
                    'results_received': True
                }
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            processed_results = _process_ai_results(analysis_results, analysis_type)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            self.update_state(
                state='SUCCESS',
                meta={
                    'progress': 100,
                    'status': 'AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
                    'analysis_type': analysis_type,
                    'processed_count': len(processed_results.get('results', []))
                }
            )
            
            result = {
                'status': 'completed',
                'analysis_type': analysis_type,
                'results': processed_results,
                'stats': {
                    'total_documents': len(documents_data.get('documents', [])),
                    'processed_documents': len(processed_results.get('results', [])),
                    'processing_time': processed_results.get('processing_time'),
                    'confidence_scores': processed_results.get('confidence_stats')
                },
                'processed_at': datetime.utcnow().isoformat()
            }
            
            logger.info(f"‚úÖ AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_results.get('results', []))} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return result
            
        else:
            error_msg = f"GPU —Å–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {response.status_code} - {response.text}"
            logger.error(f"‚ùå {error_msg}")
            return {
                'status': 'error',
                'error': error_msg,
                'analysis_type': analysis_type,
                'processed_at': datetime.utcnow().isoformat()
            }
    
    except requests.exceptions.Timeout:
        error_msg = "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPU —Å–µ—Ä–≤–µ—Ä—É"
        logger.error(f"‚ùå {error_msg}")
        return {
            'status': 'error',
            'error': error_msg,
            'analysis_type': analysis_type,
            'processed_at': datetime.utcnow().isoformat()
        }
    
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'analysis_type': analysis_type,
            'processed_at': datetime.utcnow().isoformat()
        }


@app.task(
    bind=True,
    name='tasks.gpu_tasks.gpu_health_check',
    soft_time_limit=60,
    time_limit=90,
    max_retries=3
)
def gpu_health_check(self) -> Dict[str, Any]:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è GPU —Å–µ—Ä–≤–µ—Ä–∞ –∏ –µ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤
    
    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ GPU
    """
    from datetime import datetime
    
    logger.info("üîß –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è GPU —Å–µ—Ä–≤–µ—Ä–∞")
    
    try:
        gpu_server_url = os.getenv('GPU_SERVER_URL', 'http://localhost:8001')
        status_endpoint = f"{gpu_server_url}/gpu/status"
        
        response = requests.get(status_endpoint, timeout=30)
        
        if response.status_code == 200:
            gpu_status = response.json()
            logger.info(f"‚úÖ GPU —Å—Ç–∞—Ç—É—Å –ø–æ–ª—É—á–µ–Ω: {gpu_status}")
            
            return {
                'status': 'healthy',
                'gpu_info': gpu_status,
                'server_url': gpu_server_url,
                'checked_at': datetime.utcnow().isoformat()
            }
        else:
            error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å GPU: {response.status_code}"
            logger.error(f"‚ùå {error_msg}")
            return {
                'status': 'unhealthy',
                'error': error_msg,
                'server_url': gpu_server_url,
                'checked_at': datetime.utcnow().isoformat()
            }
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'checked_at': datetime.utcnow().isoformat()
        }


def _process_ai_results(raw_results: Dict[str, Any], analysis_type: str) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ AI –∞–Ω–∞–ª–∏–∑–∞
    
    Args:
        raw_results: –°—ã—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç GPU —Å–µ—Ä–≤–µ—Ä–∞
        analysis_type: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    """
    from datetime import datetime
    
    try:
        processed_results = {
            'results': [],
            'processing_time': raw_results.get('processing_time'),
            'confidence_stats': {
                'avg_confidence': 0.0,
                'min_confidence': 1.0,
                'max_confidence': 0.0
            }
        }
        
        confidences = []
        
        for result in raw_results.get('results', []):
            processed_result = {
                'document_id': result.get('document_id'),
                'analysis_type': analysis_type,
                'confidence': result.get('confidence', 0.0),
                'processed_at': datetime.utcnow().isoformat()
            }
            
            # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ —Ç–∏–ø—É –∞–Ω–∞–ª–∏–∑–∞
            if analysis_type == 'match_scoring':
                processed_result.update({
                    'match_score': result.get('match_score', 0.0),
                    'matching_skills': result.get('matching_skills', []),
                    'missing_skills': result.get('missing_skills', []),
                    'overall_fit': result.get('overall_fit', 'unknown')
                })
            elif analysis_type == 'skills_extraction':
                processed_result.update({
                    'extracted_skills': result.get('skills', []),
                    'skill_categories': result.get('categories', {}),
                    'experience_level': result.get('experience_level', 'unknown')
                })
            elif analysis_type == 'sentiment_analysis':
                processed_result.update({
                    'sentiment': result.get('sentiment', 'neutral'),
                    'sentiment_score': result.get('sentiment_score', 0.0),
                    'key_phrases': result.get('key_phrases', [])
                })
            
            processed_results['results'].append(processed_result)
            confidences.append(result.get('confidence', 0.0))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidences:
            processed_results['confidence_stats'] = {
                'avg_confidence': sum(confidences) / len(confidences),
                'min_confidence': min(confidences),
                'max_confidence': max(confidences)
            }
        
        return processed_results
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ AI –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {
            'results': [],
            'error': str(e)
        }

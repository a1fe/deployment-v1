"""
Celery –∑–∞–¥–∞—á–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
"""

import os
import sys
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from celery import current_task, shared_task
from celery.utils.log import get_task_logger
from database.config import database
from database.operations.embedding_operations import embedding_crud
from database.operations.candidate_operations import SubmissionCRUD
from database.operations.company_operations import JobCRUD
from models.candidates import Submission
from models.companies import Job
from models.embeddings import EmbeddingMetadata
from utils.chroma_config import chroma_client, ChromaConfig
from utils.text_preprocessing import preprocess_resume_text, preprocess_job_description_text, preprocess_text_with_stats

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Celery app —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –æ–Ω –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω
def get_celery_app():
    from celery_app.celery_config import celery_app
    return celery_app

logger = get_task_logger(__name__)


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.generate_resume_embeddings')
def generate_resume_embeddings(self, submission_ids: Optional[List[str]] = None):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    
    Args:
        submission_ids: –°–ø–∏—Å–æ–∫ ID –∑–∞—è–≤–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ï—Å–ª–∏ None, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –∑–∞—è–≤–∫–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º
    """
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ")
    
    db = database.get_session()
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 5, 'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            logger.error("‚ùå ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è —Ä–µ–∑—é–º–µ
        collection = chroma_client.get_resume_collection()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 10, 'status': '–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö'})
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if submission_ids:
            submissions = []
            for submission_id in submission_ids:
                try:
                    submission_uuid = uuid.UUID(submission_id)
                    submission = SubmissionCRUD().get_by_id(db, submission_uuid)
                    if submission and getattr(submission, 'resume_raw_text', None):
                        submissions.append(submission)
                except ValueError:
                    logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç UUID –¥–ª—è –∑–∞—è–≤–∫–∏: {submission_id}")
                    continue
        else:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞—è–≤–∫–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            all_submissions = db.query(Submission).filter(
                Submission.resume_raw_text.isnot(None),
                Submission.resume_raw_text != ''
            ).all()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            submission_string_ids = [str(sub.submission_id) for sub in all_submissions]
            unprocessed_ids = embedding_crud.get_sources_without_embeddings(
                db, 'resume', submission_string_ids
            )
            submissions = [sub for sub in all_submissions if str(sub.submission_id) in unprocessed_ids]
        
        if not submissions:
            logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return {
                'status': 'completed',
                'processed_count': 0,
                'message': '–ù–µ—Ç –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'
            }
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(submissions)} —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed_count = 0
        failed_count = 0
        
        for i, submission in enumerate(submissions):
            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = 10 + (i / len(submissions)) * 80
                self.update_state(
                    state='PROGRESS', 
                    meta={
                        'progress': int(progress),
                        'status': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ {i+1}/{len(submissions)}',
                        'current_submission_id': str(submission.submission_id)
                    }
                )
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ ChromaDB
                chroma_doc_id = f"resume_{submission.submission_id}_{uuid.uuid4().hex[:8]}"
                
                # –ü–æ–ª—É—á–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ
                raw_text = getattr(submission, 'resume_raw_text', '')
                processed_text, preprocessing_stats = preprocess_text_with_stats(
                    raw_text, 
                    config=None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ä–µ–∑—é–º–µ
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                logger.info(f"üìù –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ {submission.submission_id}: "
                          f"–±—ã–ª–æ {preprocessing_stats['original_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                          f"—Å—Ç–∞–ª–æ {preprocessing_stats['processed_length']} —Å–∏–º–≤–æ–ª–æ–≤ "
                          f"(—Å–∂–∞—Ç–∏–µ: {preprocessing_stats['compression_ratio']:.2%})")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    'submission_id': str(submission.submission_id),
                    'candidate_id': submission.candidate_id,
                    'source_type': 'resume',
                    'created_at': datetime.now().isoformat(),
                    'model': ChromaConfig.EMBEDDING_MODEL,
                    'preprocessing_stats': preprocessing_stats,
                    'original_length': preprocessing_stats['original_length'],
                    'processed_length': preprocessing_stats['processed_length']
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
                if submission.candidate:
                    metadata.update({
                        'candidate_name': f"{submission.candidate.first_name} {submission.candidate.last_name}",
                        'candidate_email': submission.candidate.email
                    })
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ ChromaDB (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                collection.add(
                    documents=[processed_text],
                    metadatas=[metadata],
                    ids=[chroma_doc_id]
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                embedding_crud.create_embedding_metadata(
                    db=db,
                    source_type='resume',
                    source_id=str(submission.submission_id),
                    chroma_document_id=chroma_doc_id,
                    collection_name=ChromaConfig.RESUME_COLLECTION,
                    text_content=processed_text,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    model_name=ChromaConfig.EMBEDDING_MODEL,
                    additional_metadata=metadata
                )
                
                processed_count += 1
                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–∑—é–º–µ {submission.submission_id}")
                
            except Exception as e:
                failed_count += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ {submission.submission_id}: {str(e)}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.update_state(
            state='SUCCESS',
            meta={
                'progress': 100,
                'status': '–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                'processed_count': processed_count,
                'failed_count': failed_count,
                'total_count': len(submissions)
            }
        )
        
        logger.info(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}, –æ—à–∏–±–æ–∫: {failed_count}")
        
        return {
            'status': 'completed',
            'processed_count': processed_count,
            'failed_count': failed_count,
            'total_count': len(submissions)
        }
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–µ–∑—é–º–µ: {str(e)}")
        self.update_state(
            state='FAILURE',
            meta={
                'progress': 0,
                'status': f'–û—à–∏–±–∫–∞: {str(e)}',
                'error': str(e)
            }
        )
        raise
    finally:
        db.close()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.generate_job_embeddings')
def generate_job_embeddings(self, job_ids: Optional[List[int]] = None):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–π
    
    Args:
        job_ids: –°–ø–∏—Å–æ–∫ ID –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ï—Å–ª–∏ None, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º
    """
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π")
    
    db = database.get_session()
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 5, 'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            logger.error("‚ùå ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π
        collection = chroma_client.get_job_collection()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 10, 'status': '–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö'})
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if job_ids:
            jobs = []
            for job_id in job_ids:
                job = JobCRUD().get_by_id(db, job_id)
                if job and getattr(job, 'job_description_raw_text', None):
                    jobs.append(job)
        else:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            all_jobs = db.query(Job).filter(
                Job.job_description_raw_text.isnot(None),
                Job.job_description_raw_text != ''
            ).all()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            job_string_ids = [str(job.job_id) for job in all_jobs]
            unprocessed_ids = embedding_crud.get_sources_without_embeddings(
                db, 'job_description', job_string_ids
            )
            jobs = [job for job in all_jobs if str(job.job_id) in unprocessed_ids]
        
        if not jobs:
            logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return {
                'status': 'completed',
                'processed_count': 0,
                'message': '–ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'
            }
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(jobs)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed_count = 0
        failed_count = 0
        
        for i, job in enumerate(jobs):
            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = 10 + (i / len(jobs)) * 80
                self.update_state(
                    state='PROGRESS', 
                    meta={
                        'progress': int(progress),
                        'status': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {i+1}/{len(jobs)}',
                        'current_job_id': job.job_id
                    }
                )
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ ChromaDB
                chroma_doc_id = f"job_{job.job_id}_{uuid.uuid4().hex[:8]}"
                
                # –ü–æ–ª—É—á–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
                raw_text = getattr(job, 'job_description_raw_text', '')
                processed_text, preprocessing_stats = preprocess_text_with_stats(
                    raw_text,
                    config={
                        'remove_extra_whitespace': True,
                        'normalize_line_breaks': True,
                        'remove_duplicates': True,
                        'min_sentence_length': 10,
                        'normalize_unicode': True,
                        'preserve_structure': True,
                        'remove_empty_lines': True,
                        'max_consecutive_newlines': 2
                    }
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                logger.info(f"üìù –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: "
                          f"–±—ã–ª–æ {preprocessing_stats['original_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                          f"—Å—Ç–∞–ª–æ {preprocessing_stats['processed_length']} —Å–∏–º–≤–æ–ª–æ–≤ "
                          f"(—Å–∂–∞—Ç–∏–µ: {preprocessing_stats['compression_ratio']:.2%})")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    'job_id': job.job_id,
                    'company_id': job.company_id,
                    'source_type': 'job_description',
                    'created_at': datetime.now().isoformat(),
                    'model': ChromaConfig.EMBEDDING_MODEL,
                    'job_title': job.title or '',
                    'employment_type': job.employment_type or '',
                    'experience_level': job.experience_level or '',
                    'location': job.location or '',
                    'is_active': job.is_active if job.is_active is not None else True,
                    'preprocessing_stats': preprocessing_stats,
                    'original_length': preprocessing_stats['original_length'],
                    'processed_length': preprocessing_stats['processed_length']
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                if job.company:
                    metadata.update({
                        'company_name': job.company.name or '',
                        'company_website': job.company.website or ''
                    })
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ ChromaDB (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                collection.add(
                    documents=[processed_text],
                    metadatas=[metadata],
                    ids=[chroma_doc_id]
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                embedding_crud.create_embedding_metadata(
                    db=db,
                    source_type='job_description',
                    source_id=str(job.job_id),
                    chroma_document_id=chroma_doc_id,
                    collection_name=ChromaConfig.JOB_COLLECTION,
                    text_content=processed_text,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    model_name=ChromaConfig.EMBEDDING_MODEL,
                    additional_metadata=metadata
                )
                
                processed_count += 1
                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è {job.job_id}")
                
            except Exception as e:
                failed_count += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: {str(e)}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.update_state(
            state='SUCCESS',
            meta={
                'progress': 100,
                'status': '–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                'processed_count': processed_count,
                'failed_count': failed_count,
                'total_count': len(jobs)
            }
        )
        
        logger.info(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}, –æ—à–∏–±–æ–∫: {failed_count}")
        
        return {
            'status': 'completed',
            'processed_count': processed_count,
            'failed_count': failed_count,
            'total_count': len(jobs)
        }
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π: {str(e)}")
        self.update_state(
            state='FAILURE',
            meta={
                'progress': 0,
                'status': f'–û—à–∏–±–∫–∞: {str(e)}',
                'error': str(e)
            }
        )
        raise
    finally:
        db.close()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.search_similar_resumes')
def search_similar_resumes(self, query_text: str, limit: int = 10, min_similarity: float = 0.7):
    """
    –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
    
    Args:
        query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        min_similarity: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0)
    """
    logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query_text[:100]}...")
    
    db = database.get_session()
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Ä–µ–∑—é–º–µ
        collection = chroma_client.get_resume_collection()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = collection.query(
            query_texts=[query_text],
            n_results=limit,
            include=['documents', 'metadatas', 'distances']
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        similar_resumes = []
        if results['documents'] and results['documents'][0]:
            for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            )):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º distance –≤ similarity (ChromaDB –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, –∞ –Ω–µ —Å—Ö–æ–∂–µ—Å—Ç—å)
                similarity = 1 - distance
                
                if similarity >= min_similarity:
                    similar_resumes.append({
                        'submission_id': metadata.get('submission_id'),
                        'candidate_id': metadata.get('candidate_id'),
                        'candidate_name': metadata.get('candidate_name'),
                        'candidate_email': metadata.get('candidate_email'),
                        'similarity': round(similarity, 3),
                        'text_preview': doc[:200] + '...' if len(doc) > 200 else doc
                    })
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(similar_resumes)} –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ")
        
        return {
            'status': 'completed',
            'query': query_text,
            'results_count': len(similar_resumes),
            'similar_resumes': similar_resumes
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ: {str(e)}")
        raise
    finally:
        db.close()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.search_similar_jobs')
def search_similar_jobs(self, query_text: str, limit: int = 10, min_similarity: float = 0.7):
    """
    –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
    
    Args:
        query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        min_similarity: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0)
    """
    logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query_text[:100]}...")
    
    db = database.get_session()
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤–∞–∫–∞–Ω—Å–∏–π
        collection = chroma_client.get_job_collection()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = collection.query(
            query_texts=[query_text],
            n_results=limit,
            include=['documents', 'metadatas', 'distances']
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        similar_jobs = []
        if results['documents'] and results['documents'][0]:
            for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            )):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º distance –≤ similarity
                similarity = 1 - distance
                
                if similarity >= min_similarity:
                    similar_jobs.append({
                        'job_id': metadata.get('job_id'),
                        'company_id': metadata.get('company_id'),
                        'company_name': metadata.get('company_name'),
                        'job_title': metadata.get('job_title'),
                        'employment_type': metadata.get('employment_type'),
                        'experience_level': metadata.get('experience_level'),
                        'location': metadata.get('location'),
                        'is_active': metadata.get('is_active'),
                        'similarity': round(similarity, 3),
                        'text_preview': doc[:200] + '...' if len(doc) > 200 else doc
                    })
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(similar_jobs)} –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
        
        return {
            'status': 'completed',
            'query': query_text,
            'results_count': len(similar_jobs),
            'similar_jobs': similar_jobs
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {str(e)}")
        raise
    finally:
        db.close()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.cleanup_embeddings')
def cleanup_embeddings(self):
    """
    –û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    –£–¥–∞–ª—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
    """
    logger.info("üßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    
    db = database.get_session()
    try:
        deleted_count = 0
        
        # –û—á–∏—Å—Ç–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–µ–∑—é–º–µ
        resume_embeddings = embedding_crud.get_by_collection(db, ChromaConfig.RESUME_COLLECTION)
        resume_collection = chroma_client.get_resume_collection()
        
        for embedding in resume_embeddings:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞—è–≤–∫–∞
            try:
                submission_uuid = uuid.UUID(getattr(embedding, 'source_id'))
                submission = SubmissionCRUD().get_by_id(db, submission_uuid)
                if not submission or not getattr(submission, 'resume_raw_text', None):
                    # –£–¥–∞–ª—è–µ–º –∏–∑ ChromaDB
                    try:
                        resume_collection.delete(ids=[getattr(embedding, 'chroma_document_id')])
                    except:
                        pass  # –î–æ–∫—É–º–µ–Ω—Ç –º–æ–∂–µ—Ç —É–∂–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ ChromaDB
                    
                    # –£–¥–∞–ª—è–µ–º –∏–∑ PostgreSQL
                    db.delete(embedding)
                    deleted_count += 1
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ä–µ–∑—é–º–µ {getattr(embedding, 'source_id')}")
            except ValueError:
                # –ù–µ–≤–µ—Ä–Ω—ã–π UUID, —É–¥–∞–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                try:
                    resume_collection.delete(ids=[getattr(embedding, 'chroma_document_id')])
                except:
                    pass
                db.delete(embedding)
                deleted_count += 1
        
        # –û—á–∏—Å—Ç–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π
        job_embeddings = embedding_crud.get_by_collection(db, ChromaConfig.JOB_COLLECTION)
        job_collection = chroma_client.get_job_collection()
        
        for embedding in job_embeddings:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è
            try:
                job_id = int(getattr(embedding, 'source_id'))
                job = JobCRUD().get_by_id(db, job_id)
                if not job or not getattr(job, 'job_description_raw_text', None):
                    # –£–¥–∞–ª—è–µ–º –∏–∑ ChromaDB
                    try:
                        job_collection.delete(ids=[getattr(embedding, 'chroma_document_id')])
                    except:
                        pass  # –î–æ–∫—É–º–µ–Ω—Ç –º–æ–∂–µ—Ç —É–∂–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ ChromaDB
                    
                    # –£–¥–∞–ª—è–µ–º –∏–∑ PostgreSQL
                    db.delete(embedding)
                    deleted_count += 1
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –≤–∞–∫–∞–Ω—Å–∏–∏ {getattr(embedding, 'source_id')}")
            except (ValueError, TypeError):
                # –ù–µ–≤–µ—Ä–Ω—ã–π ID, —É–¥–∞–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                try:
                    job_collection.delete(ids=[getattr(embedding, 'chroma_document_id')])
                except:
                    pass
                db.delete(embedding)
                deleted_count += 1
        
        db.commit()
        
        logger.info(f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£–¥–∞–ª–µ–Ω–æ {deleted_count} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
        
        return {
            'status': 'completed',
            'deleted_count': deleted_count
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {str(e)}")
        raise
    finally:
        db.close()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.recreate_all_embeddings_with_preprocessing')
def recreate_all_embeddings_with_preprocessing(self, force_recreate: bool = False):
    """
    –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
    
    Args:
        force_recreate: –ï—Å–ª–∏ True, –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ.
                       –ï—Å–ª–∏ False, –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã –±–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏.
    """
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π")
    
    db = database.get_session()
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 5, 'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            logger.error("‚ùå ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        config = ChromaConfig()
        resume_collection = chroma_client.get_collection(config.resume_collection_name)
        job_collection = chroma_client.get_collection(config.job_collection_name)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 10, 'status': '–ü–æ–¥—Å—á—ë—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'})
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫ –∏ –≤–∞–∫–∞–Ω—Å–∏–π
        submission_crud = SubmissionCRUD()
        job_crud = JobCRUD()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞—è–≤–∫–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º
        all_submissions = db.query(Submission).filter(
            Submission.resume_raw_text.isnot(None),
            Submission.resume_raw_text != ''
        ).all()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
        all_jobs = db.query(Job).filter(
            Job.description.isnot(None),
            Job.description != ''
        ).all()
        
        total_submissions = len(all_submissions)
        total_jobs = len(all_jobs)
        total_items = total_submissions + total_jobs
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_submissions} —Ä–µ–∑—é–º–µ, {total_jobs} –≤–∞–∫–∞–Ω—Å–∏–π")
        
        if total_items == 0:
            logger.info("‚ÑπÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return {
                'status': 'completed',
                'processed_resumes': 0,
                'processed_jobs': 0,
                'errors': 0
            }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processed_resumes = 0
        processed_jobs = 0
        errors = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—é–º–µ
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ")
        
        for i, submission in enumerate(all_submissions):
            try:
                progress = 10 + (i / total_items) * 80
                self.update_state(
                    state='PROGRESS',
                    meta={
                        'progress': int(progress),
                        'status': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ {i + 1}/{total_submissions}',
                        'current_item': f"{submission.candidate.first_name} {submission.candidate.last_name}",
                        'processed_resumes': processed_resumes,
                        'processed_jobs': processed_jobs,
                        'errors': errors
                    }
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥
                should_recreate = force_recreate
                
                if not force_recreate:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ –±—ã–ª –ª–∏ –æ–Ω —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                    existing_embedding = embedding_crud.get_by_source_id_and_type(
                        db, str(submission.submission_id), 'resume'
                    )
                    
                    if existing_embedding:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ - –µ—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ, –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º
                        try:
                            results = resume_collection.get(
                                ids=[existing_embedding.chroma_document_id],
                                include=['metadatas']
                            )
                            
                            if results['metadatas'] and len(results['metadatas']) > 0:
                                metadata = results['metadatas'][0]
                                # –ï—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ, –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º
                                if 'preprocessing_stats' not in metadata:
                                    should_recreate = True
                                    logger.info(f"üîÑ –≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ä–µ–∑—é–º–µ {submission.submission_id} –±—É–¥–µ—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω (–±–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏)")
                                else:
                                    logger.info(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ä–µ–∑—é–º–µ {submission.submission_id} —É–∂–µ —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π")
                            else:
                                should_recreate = True
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑—é–º–µ {submission.submission_id}: {e}")
                            should_recreate = True
                    else:
                        should_recreate = True
                
                if should_recreate:
                    # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ—Å–ª–∏ –µ—Å—Ç—å
                    existing_embedding = embedding_crud.get_by_source_id_and_type(
                        db, str(submission.submission_id), 'resume'
                    )
                    
                    if existing_embedding:
                        try:
                            resume_collection.delete(ids=[existing_embedding.chroma_document_id])
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ ChromaDB: {e}")
                        
                        db.delete(existing_embedding)
                    
                    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
                    processed_text, preprocessing_stats = preprocess_text_with_stats(
                        submission.resume_raw_text,
                        config=None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ä–µ–∑—é–º–µ
                    )
                    
                    logger.info(f"üìÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ –¥–ª—è {submission.candidate.first_name} {submission.candidate.last_name}: "
                              f"–±—ã–ª–æ {preprocessing_stats['original_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                              f"—Å—Ç–∞–ª–æ {preprocessing_stats['processed_length']} —Å–∏–º–≤–æ–ª–æ–≤ "
                              f"(—Å–∂–∞—Ç–∏–µ: {preprocessing_stats['compression_ratio']:.2%})")
                    
                    # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                    embedding_response = chroma_client.create_embedding(processed_text)
                    
                    if embedding_response and 'embedding' in embedding_response:
                        chroma_doc_id = str(uuid.uuid4())
                        
                        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ
                        metadata = {
                            'submission_id': str(submission.submission_id),
                            'candidate_name': f"{submission.candidate.first_name} {submission.candidate.last_name}",
                            'candidate_email': submission.candidate.email or '',
                            'preprocessing_stats': preprocessing_stats,
                            'original_length': preprocessing_stats['original_length'],
                            'processed_length': preprocessing_stats['processed_length'],
                            'compression_ratio': preprocessing_stats['compression_ratio'],
                            'created_with_preprocessing': True,
                            'preprocessing_version': '1.0',
                            'created_at': datetime.now().isoformat()
                        }
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ ChromaDB
                        resume_collection.add(
                            documents=[processed_text],
                            embeddings=[embedding_response['embedding']],
                            metadatas=[metadata],
                            ids=[chroma_doc_id]
                        )
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ PostgreSQL
                        embedding_crud.create(db, {
                            'source_id': str(submission.submission_id),
                            'source_type': 'resume',
                            'chroma_document_id': chroma_doc_id,
                            'text_content': processed_text,
                            'metadata': metadata
                        })
                        
                        processed_resumes += 1
                        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ä–µ–∑—é–º–µ: {submission.candidate.first_name} {submission.candidate.last_name}")
                    else:
                        errors += 1
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ä–µ–∑—é–º–µ {submission.submission_id}")
                
            except Exception as e:
                errors += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—é–º–µ {submission.submission_id}: {str(e)}")
                continue
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π")
        
        for i, job in enumerate(all_jobs):
            try:
                progress = 10 + ((total_submissions + i) / total_items) * 80
                self.update_state(
                    state='PROGRESS',
                    meta={
                        'progress': int(progress),
                        'status': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {i + 1}/{total_jobs}',
                        'current_item': job.title,
                        'processed_resumes': processed_resumes,
                        'processed_jobs': processed_jobs,
                        'errors': errors
                    }
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥
                should_recreate = force_recreate
                
                if not force_recreate:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ –±—ã–ª –ª–∏ –æ–Ω —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                    existing_embedding = embedding_crud.get_by_source_id_and_type(
                        db, str(job.job_id), 'job'
                    )
                    
                    if existing_embedding:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                        try:
                            results = job_collection.get(
                                ids=[existing_embedding.chroma_document_id],
                                include=['metadatas']
                            )
                            
                            if results['metadatas'] and len(results['metadatas']) > 0:
                                metadata = results['metadatas'][0]
                                if 'preprocessing_stats' not in metadata:
                                    should_recreate = True
                                    logger.info(f"üîÑ –≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id} –±—É–¥–µ—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω (–±–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏)")
                                else:
                                    logger.info(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id} —É–∂–µ —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π")
                            else:
                                should_recreate = True
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: {e}")
                            should_recreate = True
                    else:
                        should_recreate = True
                
                if should_recreate:
                    # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ—Å–ª–∏ –µ—Å—Ç—å
                    existing_embedding = embedding_crud.get_by_source_id_and_type(
                        db, str(job.job_id), 'job'
                    )
                    
                    if existing_embedding:
                        try:
                            job_collection.delete(ids=[existing_embedding.chroma_document_id])
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ ChromaDB: {e}")
                        
                        db.delete(existing_embedding)
                    
                    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
                    processed_text, preprocessing_stats = preprocess_text_with_stats(
                        job.description,
                        config=None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π
                    )
                    
                    logger.info(f"üìÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ '{job.title}': "
                              f"–±—ã–ª–æ {preprocessing_stats['original_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                              f"—Å—Ç–∞–ª–æ {preprocessing_stats['processed_length']} —Å–∏–º–≤–æ–ª–æ–≤ "
                              f"(—Å–∂–∞—Ç–∏–µ: {preprocessing_stats['compression_ratio']:.2%})")
                    
                    # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                    embedding_response = chroma_client.create_embedding(processed_text)
                    
                    if embedding_response and 'embedding' in embedding_response:
                        chroma_doc_id = str(uuid.uuid4())
                        
                        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ
                        metadata = {
                            'job_id': str(job.job_id),
                            'job_title': job.title,
                            'company_name': job.company.company_name if job.company else '',
                            'preprocessing_stats': preprocessing_stats,
                            'original_length': preprocessing_stats['original_length'],
                            'processed_length': preprocessing_stats['processed_length'],
                            'compression_ratio': preprocessing_stats['compression_ratio'],
                            'created_with_preprocessing': True,
                            'preprocessing_version': '1.0',
                            'created_at': datetime.now().isoformat()
                        }
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ ChromaDB
                        job_collection.add(
                            documents=[processed_text],
                            embeddings=[embedding_response['embedding']],
                            metadatas=[metadata],
                            ids=[chroma_doc_id]
                        )
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ PostgreSQL
                        embedding_crud.create(db, {
                            'source_id': str(job.job_id),
                            'source_type': 'job',
                            'chroma_document_id': chroma_doc_id,
                            'text_content': processed_text,
                            'metadata': metadata
                        })
                        
                        processed_jobs += 1
                        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏: {job.title}")
                    else:
                        errors += 1
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}")
                
            except Exception as e:
                errors += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: {str(e)}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
        db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(
            state='SUCCESS',
            meta={
                'progress': 100,
                'status': '–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                'processed_resumes': processed_resumes,
                'processed_jobs': processed_jobs,
                'errors': errors
            }
        )
        
        logger.info(f"‚úÖ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. "
                   f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–∑—é–º–µ: {processed_resumes}, –≤–∞–∫–∞–Ω—Å–∏–π: {processed_jobs}, –æ—à–∏–±–æ–∫: {errors}")
        
        return {
            'status': 'completed',
            'processed_resumes': processed_resumes,
            'processed_jobs': processed_jobs,
            'errors': errors,
            'total_items': total_items
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {str(e)}")
        self.update_state(
            state='FAILURE',
            meta={
                'error': str(e),
                'status': '–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è'
            }
        )
        raise
    finally:
        db.close()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.quick_recreate_embeddings')
def quick_recreate_embeddings(self):
    """
    –ë—ã—Å—Ç—Ä–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ - —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–∑–¥–∞–Ω—ã –±–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    return recreate_all_embeddings_with_preprocessing.apply_async(args=[False]).get()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.force_recreate_all_embeddings')
def force_recreate_all_embeddings(self):
    """
    –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    """
    return recreate_all_embeddings_with_preprocessing.apply_async(args=[True]).get()


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.preprocess_resume_text_task')
def preprocess_resume_text_task(self, submission_id: str):
    """
    –ó–∞–¥–∞—á–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—é–º–µ
    
    Args:
        submission_id: ID –∑–∞—è–≤–∫–∏
    """
    try:
        session = database.get_session()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫—É
            submission = session.query(Submission).filter(
                Submission.submission_id == submission_id
            ).first()
            
            if not submission:
                raise ValueError(f"–ó–∞—è–≤–∫–∞ {submission_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            if not submission.resume_raw_text:
                raise ValueError(f"–£ –∑–∞—è–≤–∫–∏ {submission_id} –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—é–º–µ")
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            original_text = str(submission.resume_raw_text)
            processed_text = preprocess_resume_text(original_text)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
            session.query(Submission).filter(
                Submission.submission_id == submission_id
            ).update({
                'resume_raw_text': processed_text,
                'resume_parsed_at': datetime.utcnow()
            })
            
            session.commit()
            
            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ –¥–ª—è –∑–∞—è–≤–∫–∏ {submission_id} –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ü–µ—Å—Å–µ
            return {
                'submission_id': submission_id,
                'status': 'completed',
                'processed_length': len(processed_text),
                'timestamp': datetime.utcnow().isoformat()
            }
            
        finally:
            session.close()
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—é–º–µ {submission_id}: {e}")
        self.retry(countdown=60, max_retries=3)


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.preprocess_job_text_task')
def preprocess_job_text_task(self, job_id: int):
    """
    –ó–∞–¥–∞—á–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
    
    Args:
        job_id: ID –≤–∞–∫–∞–Ω—Å–∏–∏
    """
    try:
        session = database.get_session()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏—é
            job = session.query(Job).filter(Job.job_id == job_id).first()
            
            if not job:
                raise ValueError(f"–í–∞–∫–∞–Ω—Å–∏—è {job_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            if not job.description:
                raise ValueError(f"–£ –≤–∞–∫–∞–Ω—Å–∏–∏ {job_id} –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è")
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            original_text = str(job.description)
            processed_text = preprocess_job_description_text(original_text)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
            session.query(Job).filter(Job.job_id == job_id).update({
                'description': processed_text
            })
            
            session.commit()
            
            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ {job_id} –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω")
            
            return {
                'job_id': job_id,
                'status': 'completed',
                'processed_length': len(processed_text),
                'timestamp': datetime.utcnow().isoformat()
            }
            
        finally:
            session.close()
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {job_id}: {e}")
        self.retry(countdown=60, max_retries=3)


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.clear_all_embeddings_task')
def clear_all_embeddings_task(self):
    """
    –ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ ChromaDB
    """
    try:
        # –û—á–∏—â–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Ä–µ–∑—é–º–µ
        try:
            chroma_client.client.delete_collection(name="resumes")
            logger.info("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è —Ä–µ–∑—é–º–µ —É–¥–∞–ª–µ–Ω–∞")
        except Exception as e:
            logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è —Ä–µ–∑—é–º–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —É–∂–µ —É–¥–∞–ª–µ–Ω–∞: {e}")
        
        # –û—á–∏—â–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤–∞–∫–∞–Ω—Å–∏–π
        try:
            chroma_client.client.delete_collection(name="job_descriptions")
            logger.info("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π —É–¥–∞–ª–µ–Ω–∞")
        except Exception as e:
            logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è –≤–∞–∫–∞–Ω—Å–∏–π –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —É–∂–µ —É–¥–∞–ª–µ–Ω–∞: {e}")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –ø—É—Å—Ç—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        chroma_client.client.create_collection(name="resumes")
        chroma_client.client.create_collection(name="job_descriptions")
        
        logger.info("‚úÖ –í—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—á–∏—â–µ–Ω—ã, —Å–æ–∑–¥–∞–Ω—ã –Ω–æ–≤—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
        
        return {
            'status': 'completed',
            'message': '–í—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—á–∏—â–µ–Ω—ã',
            'timestamp': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
        self.retry(countdown=60, max_retries=3)


@get_celery_app().task(bind=True, name='tasks.embedding_tasks.recreate_all_embeddings_task')
def recreate_all_embeddings_task(self):
    """
    –ì–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:
    1. –û—á–∏—â–∞–µ—Ç –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç—ã
    3. –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    """
    try:
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
        
        # –®–∞–≥ 1: –û—á–∏—â–∞–µ–º –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        logger.info("üßπ –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
        clear_result = clear_all_embeddings_task.apply()
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—á–∏—Å—Ç–∫–∏: {clear_result.get()}")
        
        # –®–∞–≥ 2: –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞—è–≤–∫–∏ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏
        session = database.get_session()
        
        try:
            submissions = session.query(Submission).filter(
                Submission.resume_raw_text.isnot(None)
            ).all()
            
            jobs = session.query(Job).filter(
                Job.description.isnot(None)
            ).all()
            
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(submissions)} —Ä–µ–∑—é–º–µ –∏ {len(jobs)} –≤–∞–∫–∞–Ω—Å–∏–π")
            
        finally:
            session.close()
        
        # –®–∞–≥ 3: –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤
        logger.info("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤...")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—é–º–µ
        for submission in submissions:
            preprocess_resume_text_task.delay(str(submission.submission_id))
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏
        for job in jobs:
            preprocess_job_text_task.delay(job.job_id)
        
        # –®–∞–≥ 4: –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º countdown –¥–ª—è –∑–∞–¥–µ—Ä–∂–∫–∏, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ–ª–∞ –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è
        logger.info("‚è≥ –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
        for submission in submissions:
            generate_resume_embeddings.apply_async(
                args=[[str(submission.submission_id)]],
                countdown=60  # 60 —Å–µ–∫—É–Ω–¥ –∑–∞–¥–µ—Ä–∂–∫–∏
            )
        
        for job in jobs:
            generate_job_embeddings.apply_async(
                args=[[job.job_id]],
                countdown=60  # 60 —Å–µ–∫—É–Ω–¥ –∑–∞–¥–µ—Ä–∂–∫–∏
            )
        
        logger.info("‚úÖ –í—Å–µ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–ø—É—â–µ–Ω—ã")
        
        return {
            'status': 'completed',
            'resumes_count': len(submissions),
            'jobs_count': len(jobs),
            'message': '–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–ø—É—â–µ–Ω–æ',
            'timestamp': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
        self.retry(countdown=120, max_retries=2)

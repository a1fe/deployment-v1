"""
Celery –∑–∞–¥–∞—á–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ (–æ—á–∏—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
"""

import os
import sys
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any
import traceback

from celery import current_task, shared_task
from celery.utils.log import get_task_logger

# –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –ø—É—Ç—è–º–∏
from common.database.config import database
from common.database.operations.embedding_operations import embedding_crud
from common.database.operations.candidate_operations import SubmissionCRUD
from common.database.operations.company_operations import JobCRUD
from common.models.candidates import Submission
from common.models.companies import Job
from common.models.embeddings import EmbeddingMetadata
from common.utils.chroma_config import chroma_client, ChromaConfig
from common.utils.text_preprocessing import preprocess_resume_text, preprocess_job_description_text, preprocess_text_with_stats

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Celery app –Ω–∞–ø—Ä—è–º—É—é
from common.celery_app.celery_app import celery_app

logger = get_task_logger(__name__)


@celery_app.task(bind=True, name='common.tasks.embedding_tasks.generate_resume_embeddings')
def generate_resume_embeddings(self, submission_ids: Optional[List[str]] = None):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    
    Args:
        submission_ids: –°–ø–∏—Å–æ–∫ ID –∑–∞—è–≤–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ï—Å–ª–∏ None, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –∑–∞—è–≤–∫–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º
    """
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ")
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (UUID)
    if not (isinstance(submission_ids, list) and all(isinstance(x, str) for x in submission_ids)):
        submission_ids = None
    
    db = database.get_session()
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 5, 'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            logger.error("‚ùå ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è —Ä–µ–∑—é–º–µ
        collection = chroma_client.get_resume_collection()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 10, 'status': '–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö'})
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if submission_ids:
            submissions = []
            for submission_id in submission_ids:
                try:
                    submission_uuid = uuid.UUID(submission_id)
                    submission = SubmissionCRUD().get_by_id(db, submission_uuid)
                    if submission and getattr(submission, 'resume_raw_text', None):
                        submissions.append(submission)
                except ValueError:
                    logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç UUID –¥–ª—è –∑–∞—è–≤–∫–∏: {submission_id}")
                    continue
        else:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞—è–≤–∫–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            all_submissions = db.query(Submission).filter(
                Submission.resume_raw_text.isnot(None),
                Submission.resume_raw_text != ''
            ).all()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            submission_string_ids = [str(sub.submission_id) for sub in all_submissions]
            unprocessed_ids = embedding_crud.get_sources_without_embeddings(
                db, 'resume', submission_string_ids
            )
            submissions = [sub for sub in all_submissions if str(sub.submission_id) in unprocessed_ids]
        
        if not submissions:
            logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return {
                'status': 'completed',
                'processed_count': 0,
                'message': '–ù–µ—Ç –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'
            }
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(submissions)} —Ä–µ–∑—é–º–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed_count = 0
        failed_count = 0
        
        for i, submission in enumerate(submissions):
            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = 10 + (i / len(submissions)) * 80
                self.update_state(
                    state='PROGRESS', 
                    meta={
                        'progress': int(progress),
                        'status': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ {i+1}/{len(submissions)}',
                        'current_submission_id': str(submission.submission_id)
                    }
                )
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ ChromaDB
                chroma_doc_id = f"resume_{submission.submission_id}_{uuid.uuid4().hex[:8]}"
                
                # –ü–æ–ª—É—á–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ
                raw_text = getattr(submission, 'resume_raw_text', '')
                processed_text, preprocessing_stats = preprocess_text_with_stats(
                    raw_text, 
                    config=None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ä–µ–∑—é–º–µ
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                logger.info(f"üìù –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ {submission.submission_id}: "
                          f"–±—ã–ª–æ {preprocessing_stats['original_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                          f"—Å—Ç–∞–ª–æ {preprocessing_stats['processed_length']} —Å–∏–º–≤–æ–ª–æ–≤ "
                          f"(—Å–∂–∞—Ç–∏–µ: {preprocessing_stats['compression_ratio']:.2%})")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    'submission_id': str(submission.submission_id),
                    'candidate_id': submission.candidate_id,
                    'source_type': 'resume',
                    'created_at': datetime.now().isoformat(),
                    'model': ChromaConfig.EMBEDDING_MODEL,
                    'original_length': preprocessing_stats['original_length'],
                    'processed_length': preprocessing_stats['processed_length'],
                    'compression_ratio': round(preprocessing_stats['compression_ratio'], 4)
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
                if submission.candidate:
                    metadata.update({
                        'candidate_name': f"{submission.candidate.first_name} {submission.candidate.last_name}",
                        'candidate_email': submission.candidate.email
                    })
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ ChromaDB (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                collection.add(
                    documents=[processed_text],
                    metadatas=[metadata],
                    ids=[chroma_doc_id]
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                embedding_crud.create_embedding_metadata(
                    db=db,
                    source_type='resume',
                    source_id=str(submission.submission_id),
                    chroma_document_id=chroma_doc_id,
                    collection_name=ChromaConfig.RESUME_COLLECTION,
                    text_content=processed_text,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    model_name=ChromaConfig.EMBEDDING_MODEL,
                    additional_metadata=metadata
                )
                
                processed_count += 1
                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–∑—é–º–µ {submission.submission_id}")
                
            except Exception as e:
                failed_count += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ {submission.submission_id}: {str(e)}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.update_state(
            state='SUCCESS',
            meta={
                'progress': 100,
                'status': '–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                'processed_count': processed_count,
                'failed_count': failed_count,
                'total_count': len(submissions)
            }
        )
        
        logger.info(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}, –æ—à–∏–±–æ–∫: {failed_count}")
        
        return {
            'status': 'completed',
            'processed_count': processed_count,
            'failed_count': failed_count,
            'total_count': len(submissions)
        }
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–µ–∑—é–º–µ: {str(e)}")
        tb = traceback.format_exc()
        self.update_state(
            state='FAILURE',
            meta={
                'progress': 0,
                'status': f'–û—à–∏–±–∫–∞: {str(e)}',
                'error_type': type(e).__name__,
                'error_message': str(e),
                'traceback': tb
            }
        )
        return {
            'status': 'failed',
            'error_type': type(e).__name__,
            'error_message': str(e),
            'traceback': tb
        }
    finally:
        db.close()


@celery_app.task(bind=True, name='common.tasks.embedding_tasks.generate_job_embeddings')
def generate_job_embeddings(self, job_ids: Optional[List[int]] = None):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–π
    
    Args:
        job_ids: –°–ø–∏—Å–æ–∫ ID –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ï—Å–ª–∏ None, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º
    """
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π")
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å–ø–∏—Å–æ–∫ int
    if not (isinstance(job_ids, list) and all(isinstance(x, int) for x in job_ids)):
        job_ids = None
    
    db = database.get_session()
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 5, 'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            logger.error("‚ùå ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π
        collection = chroma_client.get_job_collection()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.update_state(state='PROGRESS', meta={'progress': 10, 'status': '–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö'})
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if job_ids:
            jobs = []
            for job_id in job_ids:
                job = JobCRUD().get_by_id(db, job_id)
                if job and getattr(job, 'job_description_raw_text', None):
                    jobs.append(job)
        else:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            all_jobs = db.query(Job).filter(
                Job.job_description_raw_text.isnot(None),
                Job.job_description_raw_text != ''
            ).all()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            job_string_ids = [str(job.job_id) for job in all_jobs]
            unprocessed_ids = embedding_crud.get_sources_without_embeddings(
                db, 'job_description', job_string_ids
            )
            jobs = [job for job in all_jobs if str(job.job_id) in unprocessed_ids]
        
        if not jobs:
            logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return {
                'status': 'completed',
                'processed_count': 0,
                'message': '–ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'
            }
        
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(jobs)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed_count = 0
        failed_count = 0
        
        for i, job in enumerate(jobs):
            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = 10 + (i / len(jobs)) * 80
                self.update_state(
                    state='PROGRESS', 
                    meta={
                        'progress': int(progress),
                        'status': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {i+1}/{len(jobs)}',
                        'current_job_id': job.job_id
                    }
                )
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ ChromaDB
                chroma_doc_id = f"job_{job.job_id}_{uuid.uuid4().hex[:8]}"
                
                # –ü–æ–ª—É—á–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
                raw_text = getattr(job, 'job_description_raw_text', '')
                processed_text, preprocessing_stats = preprocess_text_with_stats(
                    raw_text,
                    config={
                        'remove_extra_whitespace': True,
                        'normalize_line_breaks': True,
                        'remove_duplicates': True,
                        'min_sentence_length': 10,
                        'normalize_unicode': True,
                        'preserve_structure': True,
                        'remove_empty_lines': True,
                        'max_consecutive_newlines': 2
                    }
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                logger.info(f"üìù –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: "
                          f"–±—ã–ª–æ {preprocessing_stats['original_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                          f"—Å—Ç–∞–ª–æ {preprocessing_stats['processed_length']} —Å–∏–º–≤–æ–ª–æ–≤ "
                          f"(—Å–∂–∞—Ç–∏–µ: {preprocessing_stats['compression_ratio']:.2%})")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    'job_id': job.job_id,
                    'company_id': job.company_id,
                    'source_type': 'job_description',
                    'created_at': datetime.now().isoformat(),
                    'model': ChromaConfig.EMBEDDING_MODEL,
                    'job_title': job.title or '',
                    'employment_type': job.employment_type or '',
                    'experience_level': job.experience_level or '',
                    'location': job.location or '',
                    'is_active': job.is_active if job.is_active is not None else True,
                    'original_length': preprocessing_stats['original_length'],
                    'processed_length': preprocessing_stats['processed_length'],
                    'compression_ratio': round(preprocessing_stats['compression_ratio'], 4)
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                if job.company:
                    metadata.update({
                        'company_name': job.company.name or '',
                        'company_website': job.company.website or ''
                    })
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ ChromaDB (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                collection.add(
                    documents=[processed_text],
                    metadatas=[metadata],
                    ids=[chroma_doc_id]
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
                embedding_crud.create_embedding_metadata(
                    db=db,
                    source_type='job_description',
                    source_id=str(job.job_id),
                    chroma_document_id=chroma_doc_id,
                    collection_name=ChromaConfig.JOB_COLLECTION,
                    text_content=processed_text,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    model_name=ChromaConfig.EMBEDDING_MODEL,
                    additional_metadata=metadata
                )
                
                processed_count += 1
                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è {job.job_id}")
                
            except Exception as e:
                failed_count += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ {job.job_id}: {str(e)}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.update_state(
            state='SUCCESS',
            meta={
                'progress': 100,
                'status': '–ó–∞–≤–µ—Ä—à–µ–Ω–æ',
                'processed_count': processed_count,
                'failed_count': failed_count,
                'total_count': len(jobs)
            }
        )
        
        logger.info(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}, –æ—à–∏–±–æ–∫: {failed_count}")
        
        return {
            'status': 'completed',
            'processed_count': processed_count,
            'failed_count': failed_count,
            'total_count': len(jobs)
        }
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π: {str(e)}")
        tb = traceback.format_exc()
        self.update_state(
            state='FAILURE',
            meta={
                'progress': 0,
                'status': f'–û—à–∏–±–∫–∞: {str(e)}',
                'error_type': type(e).__name__,
                'error_message': str(e),
                'traceback': tb
            }
        )
        return {
            'status': 'failed',
            'error_type': type(e).__name__,
            'error_message': str(e),
            'traceback': tb
        }
    finally:
        db.close()


@celery_app.task(bind=True, name='common.tasks.embedding_tasks.search_similar_resumes')
def search_similar_resumes(self, query_text: str, limit: int = 10, min_similarity: float = 0.7):
    """
    –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
    
    Args:
        query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        min_similarity: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0)
    """
    logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query_text[:100]}...")
    
    db = database.get_session()
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Ä–µ–∑—é–º–µ
        collection = chroma_client.get_resume_collection()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = collection.query(
            query_texts=[query_text],
            n_results=limit,
            include=['documents', 'metadatas', 'distances']
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        similar_resumes = []
        if results['documents'] and results['documents'][0]:
            for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            )):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º distance –≤ similarity (ChromaDB –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, –∞ –Ω–µ —Å—Ö–æ–∂–µ—Å—Ç—å)
                similarity = 1 - distance
                
                if similarity >= min_similarity:
                    similar_resumes.append({
                        'submission_id': metadata.get('submission_id'),
                        'candidate_id': metadata.get('candidate_id'),
                        'candidate_name': metadata.get('candidate_name'),
                        'candidate_email': metadata.get('candidate_email'),
                        'similarity': round(similarity, 3),
                        'text_preview': doc[:200] + '...' if len(doc) > 200 else doc
                    })
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(similar_resumes)} –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ")
        
        return {
            'status': 'completed',
            'query': query_text,
            'results_count': len(similar_resumes),
            'similar_resumes': similar_resumes
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–∑—é–º–µ: {str(e)}")
        raise
    finally:
        db.close()


@celery_app.task(bind=True, name='common.tasks.embedding_tasks.search_similar_jobs')
def search_similar_jobs(self, query_text: str, limit: int = 10, min_similarity: float = 0.7):
    """
    –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
    
    Args:
        query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        min_similarity: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0)
    """
    logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query_text[:100]}...")
    
    db = database.get_session()
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ChromaDB
        if not chroma_client.health_check():
            raise Exception("ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –≤–∞–∫–∞–Ω—Å–∏–π
        collection = chroma_client.get_job_collection()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = collection.query(
            query_texts=[query_text],
            n_results=limit,
            include=['documents', 'metadatas', 'distances']
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        similar_jobs = []
        if results['documents'] and results['documents'][0]:
            for i, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            )):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º distance –≤ similarity
                similarity = 1 - distance
                
                if similarity >= min_similarity:
                    similar_jobs.append({
                        'job_id': metadata.get('job_id'),
                        'company_id': metadata.get('company_id'),
                        'company_name': metadata.get('company_name'),
                        'job_title': metadata.get('job_title'),
                        'employment_type': metadata.get('employment_type'),
                        'experience_level': metadata.get('experience_level'),
                        'location': metadata.get('location'),
                        'is_active': metadata.get('is_active'),
                        'similarity': round(similarity, 3),
                        'text_preview': doc[:200] + '...' if len(doc) > 200 else doc
                    })
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(similar_jobs)} –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
        
        return {
            'status': 'completed',
            'query': query_text,
            'results_count': len(similar_jobs),
            'similar_jobs': similar_jobs
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {str(e)}")
        raise
    finally:
        db.close()


@celery_app.task(bind=True, name='common.tasks.embedding_tasks.generate_all_embeddings')
def generate_all_embeddings(self, previous_results=None) -> Dict[str, Any]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–π
    (–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è —Ç–µ–ø–µ—Ä—å –Ω–∞ —É—Ä–æ–≤–Ω–µ workflow, –∑–∞–¥–∞—á–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    """
    logger.info("üîÑ –í—ã–∑–≤–∞–Ω–∞ –∑–∞–¥–∞—á–∞ generate_all_embeddings (–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Ç–æ—á–∫–∞ –≤ pipeline, –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á)")
    return {
        'status': 'skipped',
        'message': '–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ç–µ–ø–µ—Ä—å orchestrated –Ω–∞ —É—Ä–æ–≤–Ω–µ workflow',
        'timestamp': datetime.now().isoformat(),
        'previous_results': previous_results
    }

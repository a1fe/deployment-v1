"""
Fillout API tasks for retrieving resume and company data - –ü–û–õ–ù–ê–Ø –í–ï–†–°–ò–Ø
–≠—Ç–æ—Ç —Ñ–∞–π–ª –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Fillout –≤ PostgreSQL
"""

import os
import requests
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from celery.utils.log import get_task_logger
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from sqlalchemy import text
from uuid import UUID

from celery_app.celery_app import celery_app
from database.config import database
from models.candidates import (
    Submission, Candidate, Address, Education, SalaryExpectation,
    submission_competencies, submission_roles, submission_industries, submission_locations
)
from models.companies import Company, CompanyContact, Job
from models.dictionaries import Competency, Role, Industry, Location

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = get_task_logger(__name__)

# –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π Fillout –Ω–∞ –ø–æ–ª—è –ë–î –¥–ª—è —Ä–µ–∑—é–º–µ
RESUME_FIELD_MAPPING = {
    'mr5P7iiQVH2XPN2hpdM6WD': {'target': 'submission', 'field': 'resume_url', 'type': 'file_upload'},
    '6apz': {'target': 'candidate', 'field': 'linkedin_url', 'type': 'url'},
    'uu1C': {'target': 'submission', 'field': 'agree_to_processing', 'type': 'boolean'},
    '4iAc': {'target': 'submission', 'field': 'agree_to_contact', 'type': 'boolean'},
    'nbDc': {'target': 'candidate', 'field': 'first_name', 'type': 'string'},
    'qNmBUPjoEAT5EB48JqpboY': {'target': 'candidate', 'field': 'last_name', 'type': 'string'},
    'b4az': {'target': 'candidate', 'field': 'email', 'type': 'email'},
    'eyLk': {'target': 'candidate', 'field': 'mobile_number', 'type': 'phone'},
    'dnDn': {'target': 'address', 'field': 'full_address', 'type': 'address'},
    'kudR': {'target': 'submission', 'field': 'legally_authorized_us', 'type': 'boolean_yes_no'},
    '7oqB': {'target': 'submission', 'field': 'requires_sponsorship', 'type': 'boolean_yes_no'},
    '9BDD': {'target': 'education', 'field': 'degree_level', 'type': 'checkboxes'},
    'ucUj': {'target': 'education', 'field': 'field_of_study', 'type': 'checkboxes'},
    '4PHP': {'target': 'education', 'field': 'other_degree_level', 'type': 'string'},
    'rvG4': {'target': 'education', 'field': 'other_field_of_study', 'type': 'string'},
    'vjou': {'target': 'competencies', 'field': 'competency_names', 'type': 'checkboxes'},
    'v3Wv': {'target': 'submission', 'field': 'work_preference', 'type': 'dropdown'},
    'eJKT': {'target': 'submission', 'field': 'willingness_to_travel', 'type': 'number'},
    '18we': {'target': 'submission', 'field': 'willing_to_relocate', 'type': 'dropdown'},
    '6E6Q': {'target': 'locations', 'field': 'location_names', 'type': 'checkboxes'},
    'ejRB': {'target': 'submission', 'field': 'specific_locations_preferred', 'type': 'string'},
    'vk5R': {'target': 'submission', 'field': 'pe_license', 'type': 'boolean'},
    '4MbL': {'target': 'submission', 'field': 'available_shifts', 'type': 'checkboxes'},
    'dNQc': {'target': 'roles', 'field': 'role_names', 'type': 'checkboxes'},
    'mbxY': {'target': 'industries', 'field': 'industry_names', 'type': 'checkboxes'},
    '571H': {'target': 'salary', 'field': 'max_salary', 'type': 'number'},
    'oB7Z': {'target': 'salary', 'field': 'min_salary', 'type': 'number'},
    '86oT': {'target': 'salary', 'field': 'currency', 'type': 'dropdown'},
}

# –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π Fillout –Ω–∞ –ø–æ–ª—è –ë–î –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π
COMPANY_FIELD_MAPPING = {
    '8xsW': {'target': 'job', 'field': 'title', 'type': 'string'},
    '7uVa': {'target': 'company', 'field': 'name', 'type': 'string'},
    '7UTC': {'target': 'company_industries', 'field': 'industry_names', 'type': 'checkboxes'},
    'ntg7': {'target': 'contact', 'field': 'full_name', 'type': 'string'},
    'jBg7': {'target': 'job', 'field': 'job_description_url', 'type': 'file_upload'},
    'pPkE': {'target': 'contact', 'field': 'email', 'type': 'email'},
    'bAgc': {'target': 'unknown', 'field': 'company_logo', 'type': 'file_upload'},
    'wTac': {'target': 'company', 'field': 'website', 'type': 'url'},
    'qWjN': {'target': 'unknown', 'field': 'additional_file', 'type': 'file_upload'},
    'wMDm': {'target': 'job', 'field': 'description', 'type': 'long_text'},
    # –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–æ–ª—è
    'hqBS': {'target': 'unknown', 'field': 'unknown_field_1', 'type': 'json'},
    'ranB': {'target': 'unknown', 'field': 'unknown_field_2', 'type': 'json'},
    'tkfM': {'target': 'unknown', 'field': 'unknown_field_3', 'type': 'json'},
    'dd45': {'target': 'unknown', 'field': 'unknown_field_4', 'type': 'json'},
}


@celery_app.task(
    bind=True,
    name='tasks.fillout_tasks.fetch_resume_data',
    soft_time_limit=1800,
    time_limit=2100,
    max_retries=2
)
def fetch_resume_data(self) -> Dict[str, Any]:
    """
    Task 1A: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ –∏–∑ Fillout API —Å –ø–æ–ª–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –ø–æ–ª–µ–π
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π, —Å—Ç–∞—Ç—É—Å
    """
    logger.info("üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ –∏–∑ Fillout")
    
    try:
        api_key = os.getenv('FILLOUT_API_KEY')
        base_url = os.getenv('FILLOUT_BASE_URL')
        form_id = os.getenv('CV_FORM_ID')
        
        if not all([api_key, base_url, form_id]):
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Fillout API")
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        all_submissions = []
        page = 1
        limit = 150
        
        while True:
            url = f"{base_url}/api/forms/{form_id}/submissions"
            params = {
                'limit': limit,
                'offset': (page - 1) * limit
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=60)
            response.raise_for_status()
            
            data = response.json()
            page_submissions = data.get('responses', [])
            
            if not page_submissions:
                break
                
            all_submissions.extend(page_submissions)
            
            total_responses = data.get('totalResponses', 0)
            if len(all_submissions) >= total_responses:
                break
                
            page += 1
            logger.info(f"üìÑ –ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page-1}, –∑–∞–ø–∏—Å–µ–π: {len(page_submissions)}")
        
        logger.info(f"üìä –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(all_submissions)}")
        
        if not all_submissions:
            logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –≤ Fillout")
            return {
                'status': 'completed',
                'new_records': 0,
                'total_processed': 0
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        db = database.get_session()
        new_records = 0
        
        try:
            for submission_data in all_submissions:
                submission_id = submission_data.get('submissionId')
                
                if not submission_id:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –∑–∞–ø–∏—Å—å
                existing = db.query(Submission).filter(
                    Submission.submission_id == submission_id
                ).first()
                
                if existing:
                    continue
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                try:
                    # –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏
                    result = _process_resume_submission(db, submission_data)
                    if result:
                        # –ö–æ–º–º–∏—Ç–∏–º —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        db.commit()
                        new_records += 1
                        logger.info(f"‚úÖ –ó–∞–ø–∏—Å—å {submission_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ë–î")
                    else:
                        # –ï—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç—É –∑–∞–ø–∏—Å—å
                        db.rollback()
                        logger.warning(f"‚ö†Ô∏è –ó–∞–ø–∏—Å—å {submission_id} –Ω–µ –±—ã–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
                        
                except Exception as record_error:
                    # –û—Ç–∫–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â—É—é –∑–∞–ø–∏—Å—å
                    db.rollback()
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏ {submission_id}: {record_error}")
                    continue
            
            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {new_records} –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            if new_records > 0:
                logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ–∑—é–º–µ...")
                try:
                    from tasks.parsing_tasks import parse_resume_text
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–∫ Celery –∑–∞–¥–∞—á—É
                    task_result = parse_resume_text.delay()
                    logger.info(f"üìä –ó–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–ø—É—â–µ–Ω–∞: {task_result.id}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            
            return {
                'status': 'completed',
                'new_records': new_records,
                'total_processed': len(all_submissions)
            }
            
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'new_records': 0
        }


def _process_resume_submission(db: Session, submission_data: Dict[str, Any]) -> bool:
    """
    –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ —Ä–µ–∑—é–º–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        db: –°–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        submission_data: –î–∞–Ω–Ω—ã–µ –∏–∑ Fillout
        
    Returns:
        True –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
    """
    try:
        submission_id = submission_data.get('submissionId')
        logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏: {submission_id}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        questions = {q['id']: q for q in submission_data.get('questions', [])}
        extracted_data = _extract_all_resume_data(questions)
        
        # 1. –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –Ω–∞—Ö–æ–¥–∏–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        candidate = _get_or_create_candidate(db, extracted_data['candidate'])
        
        # 2. –°–æ–∑–¥–∞–µ–º submission
        submission = _create_full_submission(submission_data, extracted_data['submission'], candidate.candidate_id)
        db.add(submission)
        db.flush()  # –ü–æ–ª—É—á–∞–µ–º UUID
        
        # 3. –°–æ–∑–¥–∞–µ–º –∞–¥—Ä–µ—Å
        if extracted_data['address']:
            address = _create_address(extracted_data['address'], submission.submission_id)
            db.add(address)
        
        # 4. –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        if extracted_data['education']:
            education = _create_education(extracted_data['education'], submission.submission_id)
            db.add(education)
        
        # 5. –°–æ–∑–¥–∞–µ–º –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è
        if extracted_data['salary']:
            salary = _create_salary_expectation(extracted_data['salary'], submission.submission_id)
            db.add(salary)
        
        # 6. –°–≤—è–∑—ã–≤–∞–µ–º –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
        if extracted_data['competencies']:
            _link_competencies(db, submission.submission_id, extracted_data['competencies'])
        
        # 7. –°–≤—è–∑—ã–≤–∞–µ–º —Ä–æ–ª–∏
        if extracted_data['roles']:
            _link_roles(db, submission.submission_id, extracted_data['roles'])
        
        # 8. –°–≤—è–∑—ã–≤–∞–µ–º –∏–Ω–¥—É—Å—Ç—Ä–∏–∏
        if extracted_data['industries']:
            _link_industries(db, submission.submission_id, extracted_data['industries'])
        
        # 9. –°–≤—è–∑—ã–≤–∞–µ–º –ª–æ–∫–∞—Ü–∏–∏
        if extracted_data['locations']:
            _link_locations(db, submission.submission_id, extracted_data['locations'])
        
        # 10. –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è –∫–∞–∫ JSON –≤ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –ø–æ–ª–µ
        if extracted_data['unknown_fields']:
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å JSON –ø–æ–ª–µ –≤ submission –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            logger.info(f"üìã –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è –¥–ª—è {submission_id}: {len(extracted_data['unknown_fields'])}")
        
        logger.info(f"‚úÖ –ó–∞–ø–∏—Å—å {submission_id} –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏ {submission_id}: {e}")
        # –û—Ç–∫–∞—Ç –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
        return False


def _extract_all_resume_data(questions: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ Fillout –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
    
    Args:
        questions: –°–ª–æ–≤–∞—Ä—å –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ Fillout
        
    Returns:
        –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
    """
    extracted = {
        'candidate': {},
        'submission': {},
        'address': {},
        'education': {},
        'salary': {},
        'competencies': [],
        'roles': [],
        'industries': [],
        'locations': [],
        'unknown_fields': {}
    }
    
    for question_id, question in questions.items():
        value = question.get('value')
        
        if question_id in RESUME_FIELD_MAPPING:
            mapping = RESUME_FIELD_MAPPING[question_id]
            target = mapping['target']
            field_name = mapping['field']
            field_type = mapping['type']
            
            processed_value = _process_field_value(value, field_type)
            
            if target in ['candidate', 'submission', 'address', 'education', 'salary']:
                extracted[target][field_name] = processed_value
            elif target in ['competencies', 'roles', 'industries', 'locations']:
                if isinstance(processed_value, list):
                    extracted[target] = processed_value
                elif processed_value:
                    extracted[target] = [processed_value]
        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è
            extracted['unknown_fields'][question_id] = {
                'name': question.get('name'),
                'type': question.get('type'),
                'value': value
            }
    
    return extracted


def _process_field_value(value: Any, field_type: str) -> Any:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ —Ç–∏–ø–∞"""
    if value is None:
        return None
    
    try:
        if field_type == 'boolean':
            return bool(value)
        elif field_type == 'boolean_yes_no':
            return str(value).lower() == 'yes'
        elif field_type == 'number':
            return float(value) if value else None
        elif field_type in ['string', 'email', 'phone', 'url', 'dropdown', 'long_text']:
            return str(value) if value else None
        elif field_type == 'file_upload':
            if isinstance(value, list) and len(value) > 0:
                return value[0].get('url') if isinstance(value[0], dict) else str(value[0])
            return str(value) if value else None
        elif field_type == 'address':
            return value if isinstance(value, dict) else None
        elif field_type == 'checkboxes':
            if isinstance(value, list):
                return value
            elif isinstance(value, str):
                return [value]
            return []
        else:
            return value
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è {value} —Ç–∏–ø–∞ {field_type}: {e}")
        return value


def _get_or_create_candidate(db: Session, candidate_data: Dict[str, Any]) -> Candidate:
    """–°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""
    email = candidate_data.get('email')
    if not email:
        raise ValueError("Email –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
    
    candidate = db.query(Candidate).filter(Candidate.email == email).first()
    
    if not candidate:
        candidate = Candidate(
            first_name=candidate_data.get('first_name', ''),
            last_name=candidate_data.get('last_name', ''),
            email=email,
            mobile_number=candidate_data.get('mobile_number'),
            linkedin_url=candidate_data.get('linkedin_url'),
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        db.add(candidate)
        db.flush()
    
    return candidate


def _create_full_submission(submission_data: Dict[str, Any], submission_fields: Dict[str, Any], candidate_id: Any) -> Submission:
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ–±—ä–µ–∫—Ç Submission —Å–æ –≤—Å–µ–º–∏ –ø–æ–ª—è–º–∏"""
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–º–µ–Ω
    work_shift_related = False
    available_shifts = None
    if submission_fields.get('available_shifts'):
        shifts = submission_fields['available_shifts']
        if isinstance(shifts, list) and shifts:
            work_shift_related = True
            available_shifts = ', '.join(shifts)
    
    submission = Submission(
        submission_id=submission_data['submissionId'],
        candidate_id=candidate_id,
        resume_url=submission_fields.get('resume_url', ''),
        agree_to_processing=submission_fields.get('agree_to_processing', False),
        agree_to_contact=submission_fields.get('agree_to_contact', False),
        status='pending',
        current_step='initial',
        submission_started=_parse_datetime(submission_data.get('submissionTime')),
        last_updated=datetime.utcnow(),
        legally_authorized_us=submission_fields.get('legally_authorized_us', False),
        requires_sponsorship=submission_fields.get('requires_sponsorship', False),
        pe_license=submission_fields.get('pe_license', False),
        work_preference=submission_fields.get('work_preference'),
        willingness_to_travel=submission_fields.get('willingness_to_travel'),
        willing_to_relocate=submission_fields.get('willing_to_relocate'),
        work_shift_related=work_shift_related,
        available_shifts=available_shifts,
        specific_locations_preferred=submission_fields.get('specific_locations_preferred')
    )
    
    return submission


def _create_address(address_data: Dict[str, Any], submission_id: Any) -> Address:
    """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç Address"""
    full_address = address_data.get('full_address', {})
    
    return Address(
        submission_id=submission_id,
        address=full_address.get('address', ''),
        city=full_address.get('city', ''),
        state_province=full_address.get('state', ''),
        zip_postal_code=full_address.get('zipCode', ''),
        country=full_address.get('country', '')
    )


def _create_education(education_data: Dict[str, Any], submission_id: Any) -> Education:
    """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç Education"""
    degree_levels = education_data.get('degree_level', [])
    fields_of_study = education_data.get('field_of_study', [])
    
    # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—Ä–æ–≤–Ω–µ–π –∏–ª–∏ –ø–æ–ª–µ–π, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫—É
    degree_level = ', '.join(degree_levels) if isinstance(degree_levels, list) else str(degree_levels or '')
    field_of_study = ', '.join(fields_of_study) if isinstance(fields_of_study, list) else str(fields_of_study or '')
    
    return Education(
        submission_id=submission_id,
        degree_level=degree_level,
        field_of_study=field_of_study,
        other_degree_level=education_data.get('other_degree_level'),
        other_field_of_study=education_data.get('other_field_of_study')
    )


def _create_salary_expectation(salary_data: Dict[str, Any], submission_id: Any) -> SalaryExpectation:
    """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç SalaryExpectation"""
    return SalaryExpectation(
        submission_id=submission_id,
        min_salary=salary_data.get('min_salary'),
        max_salary=salary_data.get('max_salary'),
        currency=salary_data.get('currency', 'USD')
    )


def _link_competencies(db: Session, submission_id: Any, competency_names: List[str]):
    """–°–≤—è–∑—ã–≤–∞–µ—Ç submission —Å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏"""
    for name in competency_names:
        if not name:
            continue
            
        # –ù–∞–π—Ç–∏ –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é
        competency = db.query(Competency).filter(Competency.name == name).first()
        if not competency:
            competency = Competency(name=name, is_primary=True)
            db.add(competency)
            db.flush()
        
        # –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑—å
        link_stmt = submission_competencies.insert().values(
            submission_id=submission_id,
            competency_id=competency.competency_id
        )
        db.execute(link_stmt)


def _link_roles(db: Session, submission_id: Any, role_names: List[str]):
    """–°–≤—è–∑—ã–≤–∞–µ—Ç submission —Å —Ä–æ–ª—è–º–∏"""
    for name in role_names:
        if not name:
            continue
            
        role = db.query(Role).filter(Role.name == name).first()
        if not role:
            role = Role(name=name)
            db.add(role)
            db.flush()
        
        link_stmt = submission_roles.insert().values(
            submission_id=submission_id,
            role_id=role.role_id
        )
        db.execute(link_stmt)


def _link_industries(db: Session, submission_id: Any, industry_names: List[str]):
    """–°–≤—è–∑—ã–≤–∞–µ—Ç submission —Å –∏–Ω–¥—É—Å—Ç—Ä–∏—è–º–∏"""
    for name in industry_names:
        if not name:
            continue
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –∏–Ω–¥—É—Å—Ç—Ä–∏—è
        industry = db.query(Industry).filter(Industry.name == name).first()
        if not industry:
            try:
                industry = Industry(name=name, is_primary=True)
                db.add(industry)
                db.flush()
            except Exception as e:
                # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥—É–±–ª–∏—Ä—É—é—â–∏–π –∫–ª—é—á), 
                # –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏–Ω–¥—É—Å—Ç—Ä–∏—é –µ—â–µ —Ä–∞–∑ –±–µ–∑ rollback
                industry = db.query(Industry).filter(Industry.name == name).first()
                if not industry:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å/–Ω–∞–π—Ç–∏ –∏–Ω–¥—É—Å—Ç—Ä–∏—é '{name}': {e}")
                    continue
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è —Å–≤—è–∑—å
            existing_link = db.execute(
                submission_industries.select().where(
                    (submission_industries.c.submission_id == submission_id) &
                    (submission_industries.c.industry_id == industry.industry_id)
                )
            ).first()
            
            if not existing_link:
                link_stmt = submission_industries.insert().values(
                    submission_id=submission_id,
                    industry_id=industry.industry_id
                )
                db.execute(link_stmt)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≤—è–∑–∞—Ç—å submission {submission_id} —Å –∏–Ω–¥—É—Å—Ç—Ä–∏–µ–π {industry.industry_id}: {e}")


def _link_locations(db: Session, submission_id: Any, location_names: List[str]):
    """–°–≤—è–∑—ã–≤–∞–µ—Ç submission —Å –ª–æ–∫–∞—Ü–∏—è–º–∏"""
    for name in location_names:
        if not name:
            continue
            
        location = db.query(Location).filter(Location.name == name).first()
        if not location:
            try:
                location = Location(name=name)
                db.add(location)
                db.flush()
            except Exception as e:
                # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª–æ–∫–∞—Ü–∏—é –µ—â–µ —Ä–∞–∑ –±–µ–∑ rollback
                location = db.query(Location).filter(Location.name == name).first()
                if not location:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å/–Ω–∞–π—Ç–∏ –ª–æ–∫–∞—Ü–∏—é '{name}': {e}")
                    continue
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è —Å–≤—è–∑—å
            existing_link = db.execute(
                submission_locations.select().where(
                    (submission_locations.c.submission_id == submission_id) &
                    (submission_locations.c.location_id == location.location_id)
                )
            ).first()
            
            if not existing_link:
                link_stmt = submission_locations.insert().values(
                    submission_id=submission_id,
                    location_id=location.location_id
                )
                db.execute(link_stmt)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≤—è–∑–∞—Ç—å submission {submission_id} —Å –ª–æ–∫–∞—Ü–∏–µ–π {location.location_id}: {e}")


@celery_app.task(
    bind=True,
    name='tasks.fillout_tasks.fetch_company_data',
    soft_time_limit=1800,
    time_limit=2100,
    max_retries=2
)
def fetch_company_data(self) -> Dict[str, Any]:
    """
    Task 1B: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ Fillout API —Å –ø–æ–ª–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –ø–æ–ª–µ–π
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π, —Å—Ç–∞—Ç—É—Å
    """
    logger.info("üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ Fillout")
    
    try:
        api_key = os.getenv('FILLOUT_API_KEY')
        base_url = os.getenv('FILLOUT_BASE_URL')
        form_id = os.getenv('JOB_FORM_ID')
        
        if not all([api_key, base_url, form_id]):
            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Fillout API")
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        all_submissions = []
        page = 1
        limit = 150
        
        while True:
            url = f"{base_url}/api/forms/{form_id}/submissions"
            params = {
                'limit': limit,
                'offset': (page - 1) * limit
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=60)
            response.raise_for_status()
            
            data = response.json()
            page_submissions = data.get('responses', [])
            
            if not page_submissions:
                break
                
            all_submissions.extend(page_submissions)
            
            total_responses = data.get('totalResponses', 0)
            if len(all_submissions) >= total_responses:
                break
                
            page += 1
            logger.info(f"üìÑ –ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page-1}, –∑–∞–ø–∏—Å–µ–π: {len(page_submissions)}")
        
        logger.info(f"üìä –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –∫–æ–º–ø–∞–Ω–∏–π: {len(all_submissions)}")
        
        if not all_submissions:
            logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –≤ Fillout")
            return {
                'status': 'completed',
                'new_records': 0,
                'total_processed': 0
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö - –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        new_records = 0
        
        for submission_data in all_submissions:
            db = database.get_session()
            try:
                result = _process_company_submission(db, submission_data)
                if result:
                    db.commit()
                    new_records += 1
                    logger.info(f"‚úÖ –ö–æ–º–ø–∞–Ω–∏—è #{new_records} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ë–î")
                else:
                    db.rollback()
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏: {e}")
                db.rollback()
            finally:
                db.close()
        
        logger.info(f"‚úÖ –ò—Ç–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {new_records} –Ω–æ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        if new_records > 0:
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π...")
            try:
                from tasks.parsing_tasks import parse_job_text
                # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–∫ Celery –∑–∞–¥–∞—á—É
                task_result = parse_job_text.delay()
                logger.info(f"üìä –ó–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–ø—É—â–µ–Ω–∞: {task_result.id}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        
        return {
            'status': 'completed',
            'new_records': new_records,
            'total_processed': len(all_submissions)
        }
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'new_records': 0
        }


def _process_company_submission(db: Session, submission_data: Dict[str, Any]) -> bool:
    """
    –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∫–æ–º–ø–∞–Ω–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        db: –°–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        submission_data: –î–∞–Ω–Ω—ã–µ –∏–∑ Fillout
        
    Returns:
        True –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
    """
    try:
        submission_id = submission_data.get('submissionId')
        logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏: {submission_id}")
        
        questions = {q['id']: q for q in submission_data.get('questions', [])}
        extracted_data = _extract_all_company_data(questions)
        
        company_name = extracted_data['company'].get('name')
        logger.info(f"üìù –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏: '{company_name}'")
        
        if not company_name:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ –≤ –∑–∞–ø–∏—Å–∏ {submission_id}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è
        existing = db.query(Company).filter(Company.name == company_name).first()
        if existing:
            logger.info(f"üìù –ö–æ–º–ø–∞–Ω–∏—è '{company_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return False
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–Ω–∏—é
        logger.info(f"‚ú® –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏: '{company_name}'")
        company = Company(
            name=company_name,
            website=extracted_data['company'].get('website'),
            description=extracted_data['job'].get('description'),
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        db.add(company)
        db.flush()
        logger.info(f"‚úÖ –ö–æ–º–ø–∞–Ω–∏—è —Å–æ–∑–¥–∞–Ω–∞ —Å ID: {company.company_id}")
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞–±–æ—Ç—É
        job_title = extracted_data['job'].get('title')
        if job_title:
            logger.info(f"üíº –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã: '{job_title}'")
            job_description = extracted_data['job'].get('description') or 'No description provided'
            job = Job(
                company_id=company.company_id,
                title=job_title,
                description=job_description,
                job_description_url=extracted_data['job'].get('job_description_url'),
                is_active=True,
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow()
            )
            db.add(job)
            logger.info(f"‚úÖ –†–∞–±–æ—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–∞–∫—Ç
        contact_name = extracted_data['contact'].get('full_name')
        if contact_name:
            logger.info(f"üë§ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–∞: '{contact_name}'")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º email –µ—Å–ª–∏ –æ–Ω –Ω–µ —É–∫–∞–∑–∞–Ω
            contact_email = extracted_data['contact'].get('email')
            if not contact_email:
                contact_email = f'contact@{company_name.lower().replace(" ", "").replace(".", "")}.com'
            
            contact = CompanyContact(
                company_id=company.company_id,
                full_name=contact_name,
                email=contact_email,
                job_title=extracted_data['contact'].get('job_title'),
                is_primary=True,
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow()
            )
            db.add(contact)
            logger.info(f"‚úÖ –ö–æ–Ω—Ç–∞–∫—Ç —Å–æ–∑–¥–∞–Ω —Å email: {contact_email}")
        
        # –°–≤—è–∑—ã–≤–∞–µ–º —Å –∏–Ω–¥—É—Å—Ç—Ä–∏—è–º–∏
        industries = extracted_data.get('company_industries', [])
        if industries:
            logger.info(f"üè≠ –°–≤—è–∑—ã–≤–∞–Ω–∏–µ —Å –∏–Ω–¥—É—Å—Ç—Ä–∏—è–º–∏: {industries}")
            # –ó–¥–µ—Å—å –ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π —Å –∏–Ω–¥—É—Å—Ç—Ä–∏—è–º–∏
            # —Ç–∞–∫ –∫–∞–∫ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã company_industries
        
        logger.info(f"‚úÖ –ö–æ–º–ø–∞–Ω–∏—è '{company_name}' —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False


def _extract_all_company_data(questions: Dict[str, Any]) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ Fillout"""
    extracted = {
        'company': {},
        'job': {},
        'contact': {},
        'company_industries': [],
        'unknown_fields': {}
    }
    
    for question_id, question in questions.items():
        value = question.get('value')
        
        if question_id in COMPANY_FIELD_MAPPING:
            mapping = COMPANY_FIELD_MAPPING[question_id]
            target = mapping['target']
            field_name = mapping['field']
            field_type = mapping['type']
            
            processed_value = _process_field_value(value, field_type)
            
            if target in ['company', 'job', 'contact']:
                extracted[target][field_name] = processed_value
            elif target == 'company_industries':
                if isinstance(processed_value, list):
                    extracted['company_industries'] = processed_value
                elif processed_value:
                    extracted['company_industries'] = [processed_value]
        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è
            extracted['unknown_fields'][question_id] = {
                'name': question.get('name'),
                'type': question.get('type'),
                'value': value
            }
    
    return extracted


def _parse_datetime(date_string: Optional[str]) -> datetime:
    """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
    if not date_string:
        return datetime.utcnow()
    
    try:
        return datetime.fromisoformat(date_string.replace('Z', '+00:00'))
    except:
        return datetime.utcnow()

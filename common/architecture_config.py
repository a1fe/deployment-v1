"""
–ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è CPU/GPU –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–µ—Ä–≤–µ—Ä–∞
"""

import os
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass


@dataclass
class ServerConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–µ—Ä–≤–µ—Ä–∞"""
    server_type: str  # 'cpu' –∏–ª–∏ 'gpu'
    is_gpu_enabled: bool
    queues: List[str]
    worker_configs: Dict[str, Dict]
    services: List[str]


class ArchitectureManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã CPU/GPU"""
    
    def __init__(self):
        self.gpu_instance_name = os.getenv('GPU_INSTANCE_NAME')
        self.is_gpu_server = bool(self.gpu_instance_name)
        self.environment = os.getenv('ENVIRONMENT', 'development')
        
    def get_server_type(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Å–µ—Ä–≤–µ—Ä–∞"""
        return 'gpu' if self.is_gpu_server else 'cpu'
    
    def get_server_config(self) -> ServerConfig:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
        server_type = self.get_server_type()
        
        if server_type == 'gpu':
            return self._get_gpu_server_config()
        else:
            return self._get_cpu_server_config()
    
    def _get_cpu_server_config(self) -> ServerConfig:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è CPU —Å–µ—Ä–≤–µ—Ä–∞"""
        # –û—á–µ—Ä–µ–¥–∏ –¥–ª—è CPU —Å–µ—Ä–≤–µ—Ä–∞
        queues = ['default', 'fillout', 'search_basic']
        
        # –ï—Å–ª–∏ GPU –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º GPU –∑–∞–¥–∞—á–∏ –≤ CPU –æ—á–µ—Ä–µ–¥–∏
        if not self.gpu_instance_name:
            queues.extend(['embeddings_cpu', 'scoring_cpu'])
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤–æ—Ä–∫–µ—Ä–æ–≤
        worker_configs = {
            'default': {
                'concurrency': 2,
                'prefetch_multiplier': 2,
                'max_tasks_per_child': 500,
                'time_limit': 300,
                'soft_time_limit': 240,
                'queues': ['default']
            },
            'fillout': {
                'concurrency': 2,
                'prefetch_multiplier': 1,
                'max_tasks_per_child': 100,
                'time_limit': 180,
                'soft_time_limit': 150,
                'queues': ['fillout']
            },
            'search_basic': {
                'concurrency': 2,
                'prefetch_multiplier': 1,
                'max_tasks_per_child': 100,
                'time_limit': 300,
                'soft_time_limit': 240,
                'queues': ['search_basic']
            }
        }
        
        # –ï—Å–ª–∏ GPU –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º CPU –≤–æ—Ä–∫–µ—Ä—ã –¥–ª—è GPU –∑–∞–¥–∞—á
        if not self.gpu_instance_name:
            worker_configs.update({
                'embeddings_cpu': {
                    'concurrency': 1,
                    'prefetch_multiplier': 1,
                    'max_tasks_per_child': 50,
                    'time_limit': 600,
                    'soft_time_limit': 540,
                    'queues': ['embeddings_cpu']
                },
                'scoring_cpu': {
                    'concurrency': 1,
                    'prefetch_multiplier': 1,
                    'max_tasks_per_child': 50,
                    'time_limit': 300,
                    'soft_time_limit': 240,
                    'queues': ['scoring_cpu']
                }
            })
        
        # –°–µ—Ä–≤–∏—Å—ã CPU —Å–µ—Ä–≤–µ—Ä–∞
        services = ['redis', 'postgresql', 'celery-beat']
        if not self.gpu_instance_name:
            services.append('gpu-monitor')  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ GPU –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
        
        return ServerConfig(
            server_type='cpu',
            is_gpu_enabled=bool(self.gpu_instance_name),
            queues=queues,
            worker_configs=worker_configs,
            services=services
        )
    
    def _get_gpu_server_config(self) -> ServerConfig:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è GPU —Å–µ—Ä–≤–µ—Ä–∞"""
        queues = ['embeddings_gpu', 'scoring_tasks', 'default']
        
        worker_configs = {
            'embeddings_gpu': {
                'concurrency': 1,
                'prefetch_multiplier': 1,
                'max_tasks_per_child': 50,
                'time_limit': 600,
                'soft_time_limit': 540,
                'queues': ['embeddings_gpu']
            },
            'scoring_tasks': {
                'concurrency': 1,
                'prefetch_multiplier': 1,
                'max_tasks_per_child': 50,
                'time_limit': 300,
                'soft_time_limit': 240,
                'queues': ['scoring_tasks']
            },
            'default_gpu': {
                'concurrency': 1,
                'prefetch_multiplier': 1,
                'max_tasks_per_child': 100,
                'time_limit': 300,
                'soft_time_limit': 240,
                'queues': ['default']
            }
        }
        
        services = ['celery-workers']
        
        return ServerConfig(
            server_type='gpu',
            is_gpu_enabled=True,
            queues=queues,
            worker_configs=worker_configs,
            services=services
        )
    
    def get_recommended_workers(self) -> List[Tuple[str, Dict]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –≤–æ—Ä–∫–µ—Ä—ã –¥–ª—è –∑–∞–ø—É—Å–∫–∞"""
        config = self.get_server_config()
        
        workers = []
        for worker_name, worker_config in config.worker_configs.items():
            workers.append((worker_name, worker_config))
        
        return workers
    
    def get_systemd_services(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ systemd —Å–µ—Ä–≤–∏—Å–æ–≤ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏"""
        config = self.get_server_config()
        
        service_mapping = {
            'redis': 'redis-server',
            'postgresql': 'postgresql',
            'celery-beat': 'hr-celery-beat',
            'celery-workers': 'hr-celery-workers',
            'gpu-monitor': 'hr-gpu-monitor'
        }
        
        return [service_mapping[service] for service in config.services if service in service_mapping]
    
    def validate_environment(self) -> Tuple[bool, List[str]]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        errors = []
        
        # –û–±—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        required_vars = ['REDIS_URL', 'DATABASE_URL']
        for var in required_vars:
            if not os.getenv(var):
                errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è: {var}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è GPU —Å–µ—Ä–≤–µ—Ä–∞
        if self.is_gpu_server:
            if not os.getenv('CUDA_VISIBLE_DEVICES'):
                errors.append("GPU —Å–µ—Ä–≤–µ—Ä: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç CUDA_VISIBLE_DEVICES")
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU –ø–∞–∫–µ—Ç–æ–≤
            try:
                import torch
                if not torch.cuda.is_available():
                    errors.append("GPU —Å–µ—Ä–≤–µ—Ä: CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ PyTorch")
            except ImportError:
                errors.append("GPU —Å–µ—Ä–≤–µ—Ä: PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                
            try:
                import sentence_transformers
            except ImportError:
                errors.append("GPU —Å–µ—Ä–≤–µ—Ä: sentence-transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è CPU —Å–µ—Ä–≤–µ—Ä–∞
        else:
            if os.getenv('CUDA_VISIBLE_DEVICES'):
                errors.append("CPU —Å–µ—Ä–≤–µ—Ä: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CUDA_VISIBLE_DEVICES (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ GPU —Å–µ—Ä–≤–µ—Ä–µ)")
        
        return len(errors) == 0, errors
    
    def get_startup_command(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–º–∞–Ω–¥—É –∑–∞–ø—É—Å–∫–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
        server_type = self.get_server_type()
        
        if server_type == 'gpu':
            return "./deployment/gpu-server/start_gpu_celery.sh"
        else:
            return "./deployment/cpu-server/start_cpu_celery.sh"
    
    def get_monitoring_config(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        if self.is_gpu_server:
            return {
                'enabled': False,
                'reason': 'GPU —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥'
            }
        
        if not self.gpu_instance_name:
            return {
                'enabled': False,
                'reason': 'GPU –∏–Ω—Å—Ç–∞–Ω—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ'
            }
        
        return {
            'enabled': True,
            'gpu_queues': ['embeddings_gpu', 'scoring_tasks'],
            'check_interval': 30,
            'max_idle_time': 600,
            'min_pending_tasks': 1
        }
    
    def print_configuration_summary(self):
        """–í—ã–≤–µ—Å—Ç–∏ —Å–≤–æ–¥–∫—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        config = self.get_server_config()
        is_valid, errors = self.validate_environment()
        
        print("=" * 60)
        print("üèóÔ∏è  –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–´ CPU/GPU")
        print("=" * 60)
        print(f"üñ•Ô∏è  –¢–∏–ø —Å–µ—Ä–≤–µ—Ä–∞: {config.server_type.upper()}")
        print(f"üéØ GPU –≤–∫–ª—é—á–µ–Ω: {'‚úÖ –î–∞' if config.is_gpu_enabled else '‚ùå –ù–µ—Ç'}")
        print(f"üåç –û–∫—Ä—É–∂–µ–Ω–∏–µ: {self.environment}")
        
        if self.gpu_instance_name:
            print(f"üöÄ GPU –∏–Ω—Å—Ç–∞–Ω—Å: {self.gpu_instance_name}")
        
        print(f"\nüìã –û—á–µ—Ä–µ–¥–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        for queue in config.queues:
            print(f"   - {queue}")
        
        print(f"\n‚öôÔ∏è  –í–æ—Ä–∫–µ—Ä—ã –¥–ª—è –∑–∞–ø—É—Å–∫–∞:")
        for worker_name, worker_config in config.worker_configs.items():
            queues_str = ', '.join(worker_config['queues'])
            print(f"   - {worker_name}: {queues_str} (concurrency: {worker_config['concurrency']})")
        
        print(f"\nüîß –°–µ—Ä–≤–∏—Å—ã:")
        for service in config.services:
            print(f"   - {service}")
        
        startup_cmd = self.get_startup_command()
        print(f"\nüöÄ –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞:")
        print(f"   {startup_cmd}")
        
        monitoring = self.get_monitoring_config()
        print(f"\nüìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU:")
        if monitoring['enabled']:
            print("   ‚úÖ –í–∫–ª—é—á–µ–Ω")
            print(f"   üìã –û—á–µ—Ä–µ–¥–∏: {', '.join(monitoring['gpu_queues'])}")
            print(f"   ‚è±Ô∏è  –ò–Ω—Ç–µ—Ä–≤–∞–ª: {monitoring['check_interval']}—Å")
            print(f"   üí§ –í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è: {monitoring['max_idle_time']}—Å")
        else:
            print(f"   ‚ùå –û—Ç–∫–ª—é—á–µ–Ω: {monitoring['reason']}")
        
        print(f"\n‚úÖ –°—Ç–∞—Ç—É—Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
        if is_valid:
            print("   üü¢ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
        else:
            print("   üî¥ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏:")
            for error in errors:
                print(f"      - {error}")
        
        print("=" * 60)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è CLI –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    import sys
    
    manager = ArchitectureManager()
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'config':
            manager.print_configuration_summary()
        
        elif command == 'validate':
            is_valid, errors = manager.validate_environment()
            if is_valid:
                print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
                sys.exit(0)
            else:
                print("‚ùå –û—à–∏–±–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
                for error in errors:
                    print(f"  - {error}")
                sys.exit(1)
        
        elif command == 'workers':
            workers = manager.get_recommended_workers()
            print("–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –≤–æ—Ä–∫–µ—Ä—ã:")
            for worker_name, config in workers:
                queues = ', '.join(config['queues'])
                print(f"  {worker_name}: {queues} (concurrency: {config['concurrency']})")
        
        elif command == 'startup':
            print(manager.get_startup_command())
        
        else:
            print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {command}")
            print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: config, validate, workers, startup")
            sys.exit(1)
    else:
        manager.print_configuration_summary()


if __name__ == '__main__':
    main()
